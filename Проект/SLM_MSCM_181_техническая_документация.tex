\documentclass[14pt,a4paper]{article} 
\usepackage[cp1251]{inputenc}
\usepackage[14pt]{extsizes} 
\usepackage[T2A]{fontenc} 
\usepackage[russian]{babel} 
\usepackage[top=20mm, bottom=20mm, left=30mm, right=10mm]{geometry} 
\usepackage{graphicx}

%\title{Анализ отзывов о лекарственных препаратах в социальных медиа} 
%\date{19.03.2019} 
%\author{} 

\begin{document} 
\begin{center} 
	\hfill \break 
	\normalsize{ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ АВТОНОМНОЕ }\\ 
	%\footnotesize{ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ}\\ 
	%\footnotesize{ВЫСШЕГО ПРОФЕССИОНАЛЬНОГО ОБРАЗОВАНИЯ}\\ 
	\normalsize{ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ }\\ 
	\normalsize{НАЦИОНАЛЬНЫЙ ИССЛЕДОВАТЕЛЬСКИЙ УНИВЕРСИТЕТ}\\ 
	\normalsize{\textbf{«ВЫСШАЯ ШКОЛА ЭКОНОМИКИ»}}\\ 
	\hfill \break 
	\normalsize{\textbf{Московский институт электроники и математики\\ им. А.Н. Тихонова}}\\ 
	\hfill \break 
	\normalsize{Студенты учебной группы МСКМ 181:\\Чертенков В.И.\\Пехтерев Д.О.\\Горчавкина А.А.\\} 
	\hfill \break 
	\hfill \break 
	\hfill \break 
	\large{Техническая документация по проектной работе\\ \textbf{"Анализ отзывов о лекарственных препаратах в социальных медиа"}}\\ 
	\hfill \break 
	\hfill \break 
	%\normalsize{Аннатация по проектной работе %Междисциплинарная курсовая работа 
	%по направлению \\01.04.04 Прикладная математика\\ 
	\hfill \break 
	%студент образовательной программы магистратуры МСКМ 181\\ 
	\hfill \break 
	%Суперкомпьютерное моделирование в науке и инженерии}\\ 
	\hfill \break 
	\hfill \break 
\end{center} 
\hfill \break 
\begin{flushright} 
	%%\normalsize{Студент Курманов И.А.}\\ 
	\hfill \break 
	\hfill \break 
	\normalsize{Руководитель проекта \\ 
		\hfill \break 
		\normalsize{Артамонов С.Ю.} 
	\end{flushright} 
	\hfill \break 
	\begin{center} Москва 2019 \end{center} 
	\thispagestyle{empty} 

 
 
  \section{Существующие компании}
 
 На рынке услуг для анализа лекарственных препаратов уже сейчас существует ряд компаний, предлагающих своим клиентам получить обратную связь от потребителей о качестве их товаров и услуг, на основе имеющихся открытых источников в Интернете.
 
   \section{Многоклассовая классификация}
   
   Задача, в которой классов, на которые нужно разделить объекты, больше, чем 2. В отличии от бинарной классификации, где возможные значения классов +/- 1.
Существует ряд методов, которые сразу решают задачу многоклассовой классификации, но в моем случае я свел задачу многоклассовой классификации к задаче бинарной классификации.

Были реализованы следующие методы:

1.	СВМ – линейный классификатор. Просто реализуется, хорошо работает с большим объемом данных, любыми типами признаков (вещественные, категориальные и разреженные).
2.	Случайный лес – строит композицию независимых друг от друга классификаторов (решающих деревьев). А после, путем голосования выбирается тот класс, к которому его отнесло большинство классификаторов
3.	Градиентный бустинг – также строит композицию классификаторов, но использует взвешенное голосование, где каждый классификатор имеет собственный вес при голосовании. А также, в отличии от СЛ, где классификаторы строятся независимо друг от друга, в бустинге базовые алгоритмы строятся друг за другом, исправляя ошибки предыдущих алгоритмов.

Набор данных
Представляет собой текстовые отзывы потребителей сервиса Amazon, извлеченные пользователем Julian McAuley, разделенных на 24 категории. Я проводил классификацию по 3 категориям из 24.

- Медицина и здоровье
- Красота и уход
- Товары для детей

Эти группы выбраны не случайно. Они относятся к близким предметным областям и используют схожу лексику, в отличии от более контрастных групп (например, если бы на ряду с медициной рассматривались электроника и кино).

Процесс обучения
Из каждой из 3-х групп было взято одинаковое количество отзывов. Далее, данные разделы на 2 группы в соотношении 70/30. На 70\% данных мы обучаем наши модели (т.н. обучающая выборка), а на оставшихся 30\% мы оцениваем их качество (т.н. тестовая выборка).


 \section{Метрики качества}
Существует несколько видов метрик качества, которые позволяют оценивать качество алгоритмов с разных сторон. Мы оценивали качество классификации тремя видами:
1.	ДОЛЯ ПРАВИЛЬНЫХ ОТВЕТОВ (Accuracy). Показывает число верных ответов к общему числу отзывов в выборке. Это самая простая и самая понятная метрика, но не всегда отражает реальную эффективность алгоритма.
2.	СРЕДНЕЕ ГАРМОНИЧЕСКОЕ (F2_мера). Объединяет показатели точности работы алгоритма и его полноту. (тоесть, на сколько хорошо алгоритм определяет ложные срабатываний и ложные пропуски)
3.	ПЛОЩАДЬ ПОД ROC-КРИВОЙ (AUC-ROC). Является распространенной метрикой в машинном обучении. Этот показатель означает вероятности того, что случайно взятый объект класса 1 получит оценку принадлежности к классу 1 выше, чем случайно взятый объект класса 0.

 \section{Результаты многоклассовой классификации}
Для всех трех методов были подобраны параметры, при которых каждый метод работает лучше всего. На рис.\ref{fig:vlad} представлены показатели качества этих трех методов, а также параметры при которых достигаются эти показатели. 


\begin{figure}[h]
  \includegraphics[width=350]{vlad.png}
  \caption{Results.}
  \label{fig:vlad}
\end{figure}

 \newpage
 
 \section{Набор данных для определения тональности}
 
 В данной работе использовался следующий набор данных: отзывы на категории товаров, представленные в разных категориях на сайте Amazon в период с мая 1996 по июль 2014 года.Набор данных был собран в файлы по категориям профессором Стэнфордского университета Джулианом Макаули.
 

	
Количество отзывов по классам тональности


$\begin{tabular}{c|f|f|ff|} 

Название категории & Положительные & Нейтральные & Отрицательные \\ 
\hline 
\hline 
"Рецензии на книги" &  7\,203\,909	&   955\,189	& 738\,943	\\ 
"Кино и Телевидение" & 1\,289\,602	& 201\,302 & 206\,629	\\ 
"Бытовая техника" & 1\,356\,067  & 	142\,257  & 190\,864 	\\ 
"Медицина и здоровье" & 279\,801  & 	33\,254  & 33\,300 	\\ 
"Компакт-диски и винилы" & 903\,002  & 	101\,824  & 92\,766 	\\ 

\hline 
\end{tabular}$


\subsection{Обработка данных}



Первым шагом в данном упражнении, переведём оценки из формата 1-5 в бинарный (-1/1), для этого воспользуемся следующей логикой:

	\begin{itemize}
		\item при overall $\in$ (1,2) присвоим значение -1, что будет означать, что отзывы данной категории имеют отрицательную тональность;
		\item при overall $\in$ (3)  не будем присваивать никакого значения, так как мы будем рассматривать задачу бинарной классификации;
		\item при overall $\in$ (4,5) присвоим значение 1, так как оставляя отзывы с такими оценками, мы можем быть уверены, что пользователь был удовлетворён своей покупкой, а значит отзыв имеет положительную тональность;
	\end{itemize}

 Имеем 5 наборов данных, состоящих из отзывов пользователей и их оценок, где в каждом наборе данных содержится приблизительно миллион записей. Так как в задачах машинного обучения важно иметь сбалансированные выборки, а в разных категориях товаров разное количество положительных и отрицательных отзывов, то была написана функция, которая считает в каждом наборе данных количество: отдельно положительных и отдельно отрицательных отзывов, берёт наименьшее из них и обрезает класс, где отзывов больше, тем самым получается равное количество положительных и отрицательных отзывов в выборке.

Далее удаляем из данных знаки препинания и другие лишние символы (отмечу, что они могут быть исследованы при более глубоком анализе) и приводим все слова к нижнему регистру.

 \section{Анализ тональности}
 
\subsection{Векторизация отзывов}
Первым этапом при анализе тех или иных текстов методами машинного обучения, текстовые данные требуется перевести в числовой формат.

Метод TF-IDF (TF — term frequency, IDF — inverse document frequency) - метод, суть которого состоит в оценке важности слова как в контексте рассматриваемого экземпляра документа, так и относительно других документов, находящихся в коллекции.
		
		Частота слов (TF) вычисляется как отношение количества вхождений конкретного слова в документе к общему количеству слов в этом документе и записывается в следующем виде:
		
		$tf(a, d) = n_a / \sum_k(n_k)$,
		
		где $n_a$ - количество вхождений слова $a$ в  документ $n$, $\sum_k(n_k)$ - общее число слов в документе $n$.
		
		Обратная частота документа (IDF) - отношение общего количества документов в коллекции $|D|$ к числу документов, где присутствует данное слово $|{d_i \in D | a \in d_i}|$ и записывается в виде:
		
		$idf(a, D) = log (|D|/|{d_i \in D | a \in d_i}|)$
		
		В конечном итоге, меру на которую данный метод опирается, можно записать следующей формулой: $tf-idf(a,d,D) = tf (a, d) * idf (a, D)$


\subsection{Логистическая регрессия}
Для решения данной задачи классификации на два класса использовалась логистическая регрессия, которая является одним из методов построения линейного классификатора и даёт оценивать апостериорные вероятности принадлежности объектов классам. 

Так как логистическая регрессия является частным случаем линейного классификатора, то стоит упомянуть, что главная идея линейного классификатора заключается в том, что признаковое пространство может быть разделено гиперплоскостью на два отдельных полупространства. В каждом из полупространств прогнозируется одно (в случае бинарной классификации, из двух) значение целевого класса. Когда это можно сделать без ошибок, то выборка признаётся линейно разделимой.

%Имеем обучающую выборку: "отзыв - тональность", которая может быть представлена в виде: $X^m = {(x_1, y_1),...,(x_m,y_m)}$
%В логистической регрессии строится линейный классификатор $a$ типа:
%
%$a(x,w) = sign(\sum^n_j_=_1 w_j*f_j(x) - w_0) = sign\langle x,w \rangle$,
%
%где 
%\begin{itemize}
%
%\item $w_j$ - вес $j$-го признака
%\item $w_0$ - порог принятия решения
%\item $w=(w_0, w_1, ..., w_n)$ - вектор весов
%\item $\langle x,w \rangle$ - скалярное произведение признаков объекта на вектор весов
%\end{itemize}
%
%Задачей является настройка вектора весов $w$ по заданной выборке $X^m$

%Логистическая регрессия отличается функцией потерь, которая служит для решения этой задачи и отвечает за минимизацию эмпирического риска, имея вид:
%
%$Q(w) = \sum_i_=_1 {ln(1+exp(-y_i*\langle x_i,w \rangle))} \rightarrow \underset{w}{min}$
%
%После того, как вектор $w$ найден, можно вычислить как классификацию для объекта $x$, так и оценить апостериорные вероятности принадлежности объекта определённому классу:
%
%\hfill \break 
%$P(y|x) = \sigma (y \langle x,w \rangle), y \in Y$, где:
%\begin{itemize}
%\item $\sigma(z) = 1/(1+e^{(-z)})$ - сигмоидная функция
%\end{itemize}

\subsection{Оценка точности классификации}
Исследователями выделяется большое количество оценки точности классификации.

Самым популярным методом является метод Accuracy: суть заключается в том, что при исследовании точности модели мы смотрим на долю правильных ответов, которая может быть записана в следующем виде:
$Base\text{Rate}=\text{argmax }\frac{1}{l}\sum_{i=1}^{\text{l}}[y_{o}=y_{i}]$
Данную формулу также принято записывать в следующем виде:
$Accuracy\text{Rate}=\frac{\text{TP+TN}}{TP+FP+FN+TN}$
\hfill \break 


\subsection{Результаты}
Результаты работы классификатора:

$\begin{tabular}{c||rrrr|} 
Название категории & AccuracyRate, \% \\ 
\hline 
\hline 
"Рецензии на книги" (рис.\ref{fig:books_q}) & 91.47\% \\ 
"Кино и Телевидение"  (рис.\ref{fig:cinema_q}) & 90.65\% \\ 
"Бытовая техника" & 89.84\% \\ 
"Медицина и здоровье"  (рис.\ref{fig:med_q}) & 85.78\%  \\ 
"Компакт-диски и винилы" & 89.32\%  \\ 


\hline 
\end{tabular}$

\begin{figure}[h]
  \includegraphics[width=350]{books_q.png}
  \caption{Метрика ACC для категории: "Рецензии на книги".}
  \label{fig:books_q}
\end{figure}

\begin{figure}[h]
  \includegraphics[width=350]{cinema_q.png}
  \caption{Метрика ACC для категории: "Кино и Телевидение".}
  \label{fig:cinema_q}
\end{figure}

\begin{figure}[h]
  \includegraphics[width=350]{med_q.png}
  \caption{Метрика ACC для категории: "Медицина и здоровье".}
  \label{fig:med_q}
\end{figure}

\medskip

\newpage

\section{Визуализация}
\subsection{Платформа Tableau Public}
При решении задачи анализа большого количества данных целесообразно применять удобные средства визуализации. В рамках нашего проекта было решено использовать платформу Tableau Public (public.tableau.com) – бесплатный редактор инфографики, позволяющий представить большинство типов данных в доступной форме. Это современное удобное средство построения разного рода зависимостей с возможностью последующей публикации на веб-ресурсах. Этот сервис позволяет работать с разными форматами данных - Microsoft Exel, Text, JSON, pdf и др. Полученные в результате рисунки автоматички сохраняютя в личном кабинете пользователя, что обеспечивает доступ к ним из любых устройств. Общий объем файлов пользователя ограничивается 10 Гб. Свое изображение можно дополнять текстом, а также прикреплять к нему гиперссылки и другие рисунки (см. рис. \ref{fig:fig1}).

\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{fig1}
	\caption{Типичный вид интерфейса платформы Tableau Public}
	\label{fig:fig1}
\end{figure} 

Соотношение занимаемой площади элементов и их порядок задается пользователем.	Результат работы можно публиковать на веб-страницах. При этом пользователь может интерактивно взаимодействовать с полотном: выделять зависимости, приближать изображение, изменять интервалы фильтрации.

\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{fig2}
	\caption{Пример инфографики, выполненной в Tableau Public}
	\label{fig:fig2}
\end{figure} 

Приобтаемые навыки работы с платформой при построении графиков ROC-кривых алгоритмов классификации, подбора параметра C и различных вспомогательных изображений будут применяться в визуализации результатов анализа нашего конечного продукта.

\subsection{Облака слов}
Если алгоритм машинного обучения обрабатывает текстовые данные, полезно иметь представление о них. В частности, для алгоритма логистической регрессии мы строим облака слов \cite{tcloud} – изображение некоторого множества слов в соответствии с их критерием значимости. Критерий значимости определяется алгоритмом машинного обучения и представляет собой дествительное положительное или отрицательное число. 

Построение облака слов в Tableau Public выполнено на примере классификации методом логичтической регрессии. Для каждой категории данных получено изображение, где значимость слова определяется его близостью к центру, размером и интенсивностью оттенка. На рис. приведдены несколько из них для сравнения. В первой паре совпадений крайне мало, хотя обе категории тесно связаны с общим понятием «досуг». Во второй паре совпадений намного больше, хотя категории и кажутся и более отдаленными. Из этого можно сделать вывод, что нельзя выделить какое-то единственное множество слов разумного объема, используемое при описании чего-либо.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.45\linewidth]{1}
	\includegraphics[width=0.45\linewidth]{2}
	\includegraphics[width=0.45\linewidth]{3}
	\includegraphics[width=0.45\linewidth]{4}
	\caption{Визуализация облака слов для разных категорий}
	\label{fig:tcloud1}
\end{figure}

\subsection{Визуализация процесса обучения}
На основе данных, полученных из метода логистическоой регрессии были построены кривые, визуализирующие процесс обучения. На рис. \ref{fig:c} видно, как зависит точность классификатора от параметра алгоритма С. Максимальная точность достигается в интервале от 1 до 10. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{c.png}
 
	\label{fig:c}
\end{figure} 
Для визуального представления точности работы классификатора удобно использовать ROC-кривые. На рис.\ref{fig:roc} такая кривая для категории Health and Personal Care. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{roc.png}
 
	\label{fig:roc}
\end{figure} 
Конечно, приведенные зависимости можно построить и пользуясь другими ресурсами, но эта работа была проделана для определения особенностей платформы редактора. На данный момент мы знаем какую структуру должны иметь данные, их объемные ограничения, а также опробовали способы построение наиболее популярных форм визуализации. Полученный опыт будет применен для оформления конечного результата нашего продукта. 

%\begin{thebibliography}{9}
%	\bibitem{tcloud} Kaser O., Lemire D. Tag-cloud drawing: Algorithms for cloud visualization //arXiv preprint cs/0703109. – 2007.
%\end{thebibliography}







\end{document}