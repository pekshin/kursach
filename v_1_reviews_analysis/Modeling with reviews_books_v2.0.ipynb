{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T09:43:07.294Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gengo.ai/datasets/15-free-sentiment-analysis-datasets-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:08:13.106370Z",
     "start_time": "2019-04-07T17:06:10.334434Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "i = 0\n",
    "reviews_lst_good= []\n",
    "reviews_lst_bad = []\n",
    "\n",
    "\n",
    "with open('Books_5.json', 'r') as f:\n",
    "        for line in f:\n",
    "            if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                reviews_lst_good.append (json.loads(line))\n",
    "            \n",
    "            elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "            if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                break\n",
    "                \n",
    "reviews_lst_good = random.shuffle(reviews_lst_good)\n",
    "reviews_lst_bad = random.shuffle(reviews_lst_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:09:54.617150Z",
     "start_time": "2019-04-07T17:09:53.157075Z"
    }
   },
   "outputs": [],
   "source": [
    "reviewerID_lst = []\n",
    "reviewerName_lst = []\n",
    "reviewText_lst = []\n",
    "overall_lst = []\n",
    "summary_lst = []\n",
    "\n",
    "# reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "for i in reviews_lst_good:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "for i in reviews_lst_bad:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "df = pd.DataFrame ()\n",
    "\n",
    "df['reviewerID'] = reviewerID_lst\n",
    "# df['reviewerName'] = reviewerName_lst\n",
    "df['reviewText'] = reviewText_lst\n",
    "df['overall'] = overall_lst\n",
    "df['summary'] = summary_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:10:48.355415Z",
     "start_time": "2019-04-07T17:10:47.710947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500001\n"
     ]
    }
   ],
   "source": [
    "df ['mark'] = 0\n",
    "df.loc[df['overall'] > 3,'mark'] = 1\n",
    "\n",
    "print (len(df[df['mark'] > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewerID, reviewText, overall, summary, mark]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['mark'] != 0)&(df['mark'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:11:41.772258Z",
     "start_time": "2019-04-07T17:11:41.266676Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:12:53.631909Z",
     "start_time": "2019-04-07T17:12:53.615111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spiritually and mentally inspiring! A book that allows you to question your morals and will help you discover who you really are!',\n",
       " \"This is one my must have books. It is a masterpiece of spirituality. I'll be the first to admit, its literary quality isn't much. It is rather simplistically written, but the message behind it is so powerful that you have to read it. It will take you to enlightenment.\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(df[df['overall'] > 3]['reviewText'][:2])\n",
    "reviews_train [:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:15:13.200759Z",
     "start_time": "2019-04-07T17:14:04.397743Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:21:41.492355Z",
     "start_time": "2019-04-07T17:16:04.680535Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:40:19.754441Z",
     "start_time": "2019-04-07T17:40:15.326999Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:41:20.794352Z",
     "start_time": "2019-04-07T17:40:16.116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8996\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.5)\n",
    "final_model.fit(X,  y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                        , final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:44:55.052366Z",
     "start_time": "2019-04-07T17:44:06.201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('klausner', 4.217558096589567)\n",
      "('ariely', 2.848116519598753)\n",
      "('everneath', 2.7092255946127577)\n",
      "('spong', 2.5704121614981528)\n",
      "('maxon', 2.5124985059202687)\n",
      "('booksneeze', -3.493254457182336)\n",
      "('waterbrook', -2.7632559624305277)\n",
      "('killgore', -2.69149943606483)\n",
      "('scarpetta', -2.6093523972060035)\n",
      "('booksneezecom', -2.5758875198341338)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T17:44:03.126313Z",
     "start_time": "2019-04-07T17:44:03.098637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('klausner', 4.217558096589567)\n",
      "('ariely', 2.848116519598753)\n",
      "('everneath', 2.7092255946127577)\n",
      "('spong', 2.5704121614981528)\n",
      "('maxon', 2.5124985059202687)\n",
      "('olaf', 2.3654402805132566)\n",
      "('ehrman', 2.358455133342693)\n",
      "('aria', 2.2955011982448776)\n",
      "('pleasantly', 2.2493119170369544)\n",
      "('margolin', 2.0781589783203493)\n",
      "('erdrich', 2.045893274820339)\n",
      "('hobb', 1.9770975521332592)\n",
      "('proses', 1.9715490922912755)\n",
      "('tamani', 1.9712774311695884)\n",
      "('maclean', 1.9689074781163967)\n",
      "('kaiden', 1.968689765074976)\n",
      "('humbert', 1.9662899890904848)\n",
      "('zinsser', 1.9507065017084348)\n",
      "('wynne', 1.9408599770903854)\n",
      "('gaiman', 1.9391932700856813)\n",
      "('wallis', 1.9284076717647278)\n",
      "('lobdell', 1.917548648755522)\n",
      "('quibble', 1.9137553831651555)\n",
      "('rollins', 1.9127985800650966)\n",
      "('refreshing', 1.9093870931130132)\n",
      "('harpercollins', 1.9052766237864243)\n",
      "('argeneau', 1.903691571827448)\n",
      "('halpern', 1.8960486023895722)\n",
      "('toole', 1.8875415002401268)\n",
      "('septimus', 1.876508140172002)\n",
      "('refreshingly', 1.8698882301786124)\n",
      "('renni', 1.8657173395748592)\n",
      "('alafair', 1.8642869416004828)\n",
      "('jacinda', 1.8625764765387438)\n",
      "('baudelaires', 1.850685784777972)\n",
      "('dany', 1.8440305015919676)\n",
      "('gitomer', 1.8366454544184714)\n",
      "('bravo', 1.8333870604627258)\n",
      "('bukowski', 1.821651557039405)\n",
      "('chinaski', 1.8210064478579973)\n",
      "('coetzee', 1.8124754319596899)\n",
      "('unearthly', 1.8045140789793854)\n",
      "('postsecret', 1.8021395831582439)\n",
      "('fayz', 1.799905317264043)\n",
      "('lashner', 1.7865888546016817)\n",
      "('crownover', 1.7784211941780872)\n",
      "('biscuit', 1.7781565233637875)\n",
      "('kerrelyn', 1.760638608121418)\n",
      "('boortz', 1.7552475249542805)\n",
      "('sobering', 1.7528405222631673)\n",
      "('lurie', 1.745655239566265)\n",
      "('lippman', 1.7425262270764612)\n",
      "('quibbles', 1.7394748215208873)\n",
      "('borgs', 1.7262190800548753)\n",
      "('lorien', 1.7252200030501068)\n",
      "('sandman', 1.7143845026074933)\n",
      "('sabriel', 1.7039618945826565)\n",
      "('enzo', 1.702306341623642)\n",
      "('wiesels', 1.7022264701451453)\n",
      "('hurston', 1.6948416644864446)\n",
      "('crombie', 1.6939775435800468)\n",
      "('shepard', 1.6929242771818258)\n",
      "('caylee', 1.682283246651364)\n",
      "('stossels', 1.6764705513954274)\n",
      "('angstrom', 1.6710515709343645)\n",
      "('vail', 1.6703429929081137)\n",
      "('getabstract', 1.6699387192577255)\n",
      "('meena', 1.665854957926333)\n",
      "('bourdain', 1.658626509436202)\n",
      "('disappoint', 1.6577305248334955)\n",
      "('eloisa', 1.652811652189258)\n",
      "('grippando', 1.6474555288492914)\n",
      "('steinbeck', 1.634486021136912)\n",
      "('punches', 1.6344350829225893)\n",
      "('jenkins', 1.633671368304611)\n",
      "('quotdeep', 1.6304377985287328)\n",
      "('patchett', 1.6300056873162074)\n",
      "('murakami', 1.622313342126066)\n",
      "('lyssa', 1.6161506622774766)\n",
      "('annabelle', 1.6160359583791637)\n",
      "('weggins', 1.6105847049285364)\n",
      "('schaums', 1.6104316713199838)\n",
      "('ranney', 1.6025929817711577)\n",
      "('ree', 1.5978708203892096)\n",
      "('apprehensive', 1.5896888606924413)\n",
      "('janelle', 1.581466735786457)\n",
      "('stegner', 1.5790856364499035)\n",
      "('langella', 1.5767023014962656)\n",
      "('shriver', 1.5670326027015362)\n",
      "('schlosser', 1.5649369905740682)\n",
      "('carmack', 1.5640217601104747)\n",
      "('monogamy', 1.5605995404434327)\n",
      "('guhrke', 1.5579781715223135)\n",
      "('pitera', 1.5538231267374216)\n",
      "('defiantly', 1.5515752737384179)\n",
      "('sugarcreek', 1.548203395335856)\n",
      "('elisa', 1.5466238613518233)\n",
      "('warrick', 1.5463412470241706)\n",
      "('allon', 1.5450599583690459)\n",
      "('fsm', 1.540963206547532)\n",
      "('kingsolver', 1.5377005840389932)\n",
      "('mckee', 1.5347094944450452)\n",
      "('discworld', 1.5340503807372798)\n",
      "('carraway', 1.5239169151187024)\n",
      "('complaint', 1.5235344673563942)\n",
      "('naysayers', 1.523523406783162)\n",
      "('roarks', 1.5195711304593669)\n",
      "('jinni', 1.5171995957046236)\n",
      "('rutledge', 1.516722689948412)\n",
      "('coetzees', 1.5155388875223068)\n",
      "('gutman', 1.5112029881304738)\n",
      "('hoffer', 1.5109291839828012)\n",
      "('gatsbys', 1.5105546526205296)\n",
      "('lehane', 1.5091748750667002)\n",
      "('lerner', 1.5090002568192538)\n",
      "('middlebrook', 1.507445183629454)\n",
      "('delightfully', 1.504944836502286)\n",
      "('sigma', 1.5012916764747595)\n",
      "('jeaniene', 1.4948926030853926)\n",
      "('avon', 1.4938558746662334)\n"
     ]
    }
   ],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:120]:\n",
    "    print (best_positive)\n",
    "\n",
    "writers = ['klausner','rollins','ehrman','gaiman','spong','olaf','steinbeck','harpercollins','discworld',\n",
    "'kingsolver','pratchett','maxon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T08:37:48.704668Z",
     "start_time": "2019-04-08T08:37:48.680362Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    \n",
    "    reviews_lst_good = random.shuffle(reviews_lst_good)\n",
    "    reviews_lst_bad = random.shuffle(reviews_lst_bad)\n",
    "                    \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "    for i in reviews_lst_good:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    for i in reviews_lst_bad:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "    df['reviewerID'] = reviewerID_lst\n",
    "    # df['reviewerName'] = reviewerName_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "    df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = CountVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    \n",
    "#     for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "#         lr = LogisticRegression(C=c)\n",
    "#         lr.fit(X_train, y_train)\n",
    "#         print (\"Accuracy for C=%s: %s\" \n",
    "#                % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "    \n",
    "    final_model = LogisticRegression(C=parametr)\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T08:37:48.664673Z",
     "start_time": "2019-04-08T07:38:21.100163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Health_and_Personal_Care_5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.938383645395491\n",
      "Accuracy for C=0.05: 0.9434330476554397\n",
      "Accuracy for C=0.25: 0.9450024564659643\n",
      "Accuracy for C=0.5: 0.9447704569026694\n",
      "Accuracy for C=1: 0.9439652819477046\n",
      "Final Accuracy: 0.7267\n",
      "('deducted', 1.6735955495548662)\n",
      "('pleased', 1.6672971408656203)\n",
      "('complaints', 1.6021844696308738)\n",
      "('blown', 1.599463842809185)\n",
      "('skeptical', 1.5973512316562286)\n",
      "('disappointing', -2.568235481354607)\n",
      "('worthless', -2.4014985591604696)\n",
      "('unacceptable', -2.2410102197616704)\n",
      "('disappointment', -2.0860850094092642)\n",
      "('poorly', -2.033562095889835)\n",
      "Movies_and_TV_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Movies_and_TV_5.json\n",
      "Accuracy for C=0.01: 0.9080730289296158\n",
      "Accuracy for C=0.05: 0.9142131447412879\n",
      "Accuracy for C=0.25: 0.9155297160633352\n",
      "Accuracy for C=0.5: 0.9149005580864277\n",
      "Accuracy for C=1: 0.9137645784059001\n",
      "Final Accuracy: 0.8645\n",
      "('coulardeau', 2.534638526778017)\n",
      "('bots', 1.8835420168687087)\n",
      "('quotable', 1.7977161111451905)\n",
      "('gm', 1.6730895346932193)\n",
      "('pleasantly', 1.6484628080082278)\n",
      "('kgharris', -2.3267783896566168)\n",
      "('waste', -2.1895868799993017)\n",
      "('pattinson', -2.1217774209512696)\n",
      "('promisingly', -2.110650715192879)\n",
      "('stinks', -2.0761853201732086)\n",
      "Electronics_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Electronics_5.json\n",
      "Accuracy for C=0.01: 0.9032179206639757\n",
      "Accuracy for C=0.05: 0.9088702993733492\n",
      "Accuracy for C=0.25: 0.9104503419450622\n",
      "Accuracy for C=0.5: 0.9101939576787088\n",
      "Accuracy for C=1: 0.9092876691092734\n",
      "Final Accuracy: 0.8949\n",
      "('boxwave', 2.1984379892117327)\n",
      "('squaretrade', 2.073878293639001)\n",
      "('hesitate', 1.9972977817706912)\n",
      "('itorch', 1.891868021435039)\n",
      "('excelente', 1.867588305289407)\n",
      "('unacceptable', -2.6469426325823986)\n",
      "('paperweight', -2.43102102796402)\n",
      "('disappointing', -2.2669812486023826)\n",
      "('steer', -2.1541965447620766)\n",
      "('returning', -2.141298751092153)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T09:01:19.267071Z",
     "start_time": "2019-04-08T08:37:48.715166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Health_and_Personal_Care_5.json\n",
      "Final Accuracy: 0.7207\n",
      "('pleased', 1.5618594321294323)\n",
      "('complaints', 1.432258377779206)\n",
      "('highly', 1.3918914288613824)\n",
      "('skeptical', 1.3768816183727184)\n",
      "('excellent', 1.3706013070559753)\n",
      "('disappointing', -2.316839332833127)\n",
      "('worthless', -2.156716678923403)\n",
      "('disappointment', -1.8826294779590422)\n",
      "('poorly', -1.8082946209058088)\n",
      "('useless', -1.7788971584198587)\n",
      "Movies_and_TV_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Movies_and_TV_5.json\n",
      "Final Accuracy: 0.86425\n",
      "('coulardeau', 1.9915162234264734)\n",
      "('bots', 1.5715109107481053)\n",
      "('pleasantly', 1.475793358260216)\n",
      "('complaint', 1.4660137803805635)\n",
      "('awsome', 1.4296317077425813)\n",
      "('waste', -2.106857424594696)\n",
      "('stinks', -1.9126083517796557)\n",
      "('tedious', -1.8410531005530322)\n",
      "('worst', -1.8249451050578414)\n",
      "('redeeming', -1.8118103334395002)\n",
      "Electronics_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Electronics_5.json\n",
      "Final Accuracy: 0.89545\n",
      "('squaretrade', 1.8687040850544532)\n",
      "('boxwave', 1.8522749398492977)\n",
      "('hesitate', 1.8239086563893006)\n",
      "('beat', 1.7239383364375958)\n",
      "('pleased', 1.5707859246288787)\n",
      "('unacceptable', -2.4641352015136984)\n",
      "('disappointing', -2.1549427983461538)\n",
      "('paperweight', -2.119545987531681)\n",
      "('returning', -2.0716257635970696)\n",
      "('returned', -1.9450243317763318)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.25)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T09:16:21.652869Z",
     "start_time": "2019-04-08T09:16:21.617085Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    reviews_lst_good = random.shuffle(reviews_lst_good)\n",
    "    reviews_lst_bad = random.shuffle(reviews_lst_bad)  \n",
    "    \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "    for i in reviews_lst_good:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    for i in reviews_lst_bad:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "    df['reviewerID'] = reviewerID_lst\n",
    "    # df['reviewerName'] = reviewerName_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "    df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = TfidfVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    print ('    ')\n",
    "    \n",
    "    for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "        lr = LogisticRegression(C=c)\n",
    "        lr.fit(X_train, y_train)\n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "    \n",
    "    final_model = LogisticRegression(C=parametr)\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T09:16:22.198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5.json\n",
      "   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Health_and_Personal_Care_5.json\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.9201239150608658\n",
      "Accuracy for C=0.05: 0.9241634368688247\n",
      "Accuracy for C=0.25: 0.9370871772476663\n",
      "Accuracy for C=0.5: 0.9413450515857853\n",
      "Accuracy for C=1: 0.9445248103062395\n",
      "Final Accuracy: 0.645\n",
      "('great', 9.248991014051073)\n",
      "('easy', 6.676706543936719)\n",
      "('love', 6.590573430885348)\n",
      "('best', 5.589211279421459)\n",
      "('works', 5.430351825654954)\n",
      "('not', -9.17523748815023)\n",
      "('waste', -6.132527616956738)\n",
      "('didnt', -5.670532708286185)\n",
      "('disappointed', -5.580901260373458)\n",
      "('return', -5.522299696565245)\n",
      "   \n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Health_and_Personal_Care_5.json\n",
      "    \n",
      "Accuracy for C=0.01: 0.9203286205578907\n",
      "Accuracy for C=0.05: 0.9242316720344997\n",
      "Accuracy for C=0.25: 0.9374965882417162\n",
      "Accuracy for C=0.5: 0.94225940280583\n",
      "Accuracy for C=1: 0.9447568098695344\n",
      "Final Accuracy: 0.67785\n",
      "('great', 10.6188904927351)\n",
      "('easy', 7.955335725239867)\n",
      "('love', 7.740038391954543)\n",
      "('best', 6.663597726359896)\n",
      "('highly', 6.657759089869975)\n",
      "('not', -10.237423574590396)\n",
      "('waste', -6.883926508993139)\n",
      "('useless', -6.405365874354659)\n",
      "('return', -6.392220022777741)\n",
      "('disappointed', -6.300578679334664)\n",
      "Movies_and_TV_5.json\n",
      "   \n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Movies_and_TV_5.json\n",
      "    \n",
      "Accuracy for C=0.01: 0.8437824045485791\n",
      "Accuracy for C=0.05: 0.8942373789744725\n",
      "Accuracy for C=0.25: 0.9115508744130771\n",
      "Accuracy for C=0.5: 0.915494762842396\n",
      "Accuracy for C=1: 0.9178075009612136\n",
      "Final Accuracy: 0.88125\n",
      "('great', 11.522030645786325)\n",
      "('excellent', 8.859852313955248)\n",
      "('perfect', 7.944617085687317)\n",
      "('best', 7.46589032304209)\n",
      "('classic', 7.220489474058792)\n",
      "('worst', -12.292322360441013)\n",
      "('waste', -11.445184081787707)\n",
      "('boring', -10.870911018180605)\n",
      "('not', -8.57934789389678)\n",
      "('terrible', -8.33269062242839)\n",
      "   \n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Movies_and_TV_5.json\n",
      "    \n",
      "Accuracy for C=0.01: 0.8445164221883047\n",
      "Accuracy for C=0.05: 0.894010183038367\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('   ')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.25)\n",
    "        gc.collect()\n",
    "        print ('   ')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T06:28:01.820387Z",
     "start_time": "2019-04-05T06:26:18.951Z"
    }
   },
   "outputs": [],
   "source": [
    "# BackUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T06:28:01.821971Z",
     "start_time": "2019-04-05T06:26:18.952Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_json('Books_5.json')\n",
    "# import ijson\n",
    "# filename = \"Books_5.json\"\n",
    "# with open(filename, 'r') as f:\n",
    "#     objects = ijson.items(f, 'meta.view.columns.item')\n",
    "#     columns = list(objects)\n",
    "#     print (objects)\n",
    "# handle = open(\"Books_5.json\", \"r\")\n",
    "\n",
    "# while True:\n",
    "#     data = handle.read(20000)\n",
    "#     if not data:\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "179.4px",
    "left": "1169px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
