{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T05:31:54.682197Z",
     "start_time": "2019-04-10T05:31:54.579863Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gengo.ai/datasets/15-free-sentiment-analysis-datasets-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T05:37:59.725562Z",
     "start_time": "2019-04-10T05:35:47.872383Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "i = 0\n",
    "reviews_lst_good= []\n",
    "reviews_lst_bad = []\n",
    "\n",
    "\n",
    "with open('C:\\\\Users\\\\denis.pekhterev\\\\Downloads\\\\Experiment_old\\\\Books_5.json', 'r') as f:\n",
    "        for line in f:\n",
    "            if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                reviews_lst_good.append (json.loads(line))\n",
    "            \n",
    "            elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "            if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                break\n",
    "                \n",
    "random.shuffle(reviews_lst_good)\n",
    "random.shuffle(reviews_lst_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T05:42:59.325635Z",
     "start_time": "2019-04-10T05:42:47.760186Z"
    }
   },
   "outputs": [],
   "source": [
    "reviewerID_lst = []\n",
    "reviewerName_lst = []\n",
    "reviewText_lst = []\n",
    "overall_lst = []\n",
    "summary_lst = []\n",
    "\n",
    "# reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "for i in reviews_lst_good:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "for i in reviews_lst_bad:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "df = pd.DataFrame ()\n",
    "\n",
    "df['reviewerID'] = reviewerID_lst\n",
    "# df['reviewerName'] = reviewerName_lst\n",
    "df['reviewText'] = reviewText_lst\n",
    "df['overall'] = overall_lst\n",
    "df['summary'] = summary_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T05:47:24.124964Z",
     "start_time": "2019-04-10T05:47:19.792406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500001\n"
     ]
    }
   ],
   "source": [
    "df ['mark'] = -1\n",
    "df.loc[df['overall'] > 3,'mark'] = 1\n",
    "\n",
    "print (len(df[df['mark'] > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T05:51:55.814698Z",
     "start_time": "2019-04-10T05:51:55.501414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewerID, reviewText, overall, summary, mark]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['mark'] != -1)&(df['mark'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T05:57:44.021133Z",
     "start_time": "2019-04-10T05:57:17.110091Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T06:01:07.984028Z",
     "start_time": "2019-04-10T06:01:07.936055Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Archer tells us about Whitechapel at the time of World War I. He misses out that Whitechapel was predominantly Jewish and it was here that the Jewish Legion (part of the British Army) was organized, paraded (right down Charlie's street) and became the model for the Jewish Brigade of World War II.\",\n",
       " \"Even though I agree with a few people the SEP books have can be a little formalistic I rated this books so high due to the great humor. I haven't laughed so hard with any other book. The heroine is written with such wit and unabashed sarcasm that you can't help laugh. The plot is fun and steamy, and yes if you have read many of SEP books a little familiar. But it's worth the read if only for the great dialog.I listened to this on Audible.com and found the narrator only helped add to the fun of the book.\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(df[df['overall'] > 3]['reviewText'][:2])\n",
    "reviews_train [:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T06:05:24.756100Z",
     "start_time": "2019-04-10T06:04:12.113496Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T06:15:29.283283Z",
     "start_time": "2019-04-10T06:09:19.512840Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T06:19:52.869348Z",
     "start_time": "2019-04-10T06:19:33.295924Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T06:40:26.131929Z",
     "start_time": "2019-04-10T06:23:46.006101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.91145\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.5)\n",
    "final_model.fit(X,  y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                        , final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T06:44:25.018518Z",
     "start_time": "2019-04-10T06:44:14.980555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('klausner', 4.147142370815207)\n",
      "('ariely', 2.813309136917886)\n",
      "('everneath', 2.725227604823884)\n",
      "('spong', 2.6095583721733715)\n",
      "('maxon', 2.527694638939319)\n",
      "('booksneeze', -3.473470371960414)\n",
      "('waterbrook', -2.7344756508000025)\n",
      "('scarpetta', -2.6240425559570726)\n",
      "('killgore', -2.62346383374639)\n",
      "('booksneezecom', -2.483382630085467)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T11:37:59.754693Z",
     "start_time": "2019-04-08T11:37:56.101655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('klausner', 4.200585683240843)\n",
      "('ariely', 2.8356831815044803)\n",
      "('everneath', 2.6124595643870463)\n",
      "('maxon', 2.548042693956325)\n",
      "('spong', 2.503794565750101)\n",
      "('olaf', 2.335943150736356)\n",
      "('ehrman', 2.2755094891117817)\n",
      "('pleasantly', 2.2397345696720072)\n",
      "('aria', 2.227326464942671)\n",
      "('margolin', 2.209052535420335)\n",
      "('erdrich', 2.016718935236432)\n",
      "('wynne', 2.001600642188314)\n",
      "('proses', 1.9956662863936512)\n",
      "('tamani', 1.9886643508909623)\n",
      "('kaiden', 1.9801171303234608)\n",
      "('hobb', 1.9683015005540692)\n",
      "('maclean', 1.952409460033418)\n",
      "('zinsser', 1.94943085254741)\n",
      "('lobdell', 1.9294905306995673)\n",
      "('argeneau', 1.925562957231128)\n",
      "('halpern', 1.915425482499514)\n",
      "('wallis', 1.9136862005436155)\n",
      "('rollins', 1.9082115838869715)\n",
      "('humbert', 1.9015820908296284)\n",
      "('refreshing', 1.9004044314727193)\n",
      "('gaiman', 1.8980815479534694)\n",
      "('quibble', 1.8979643410512592)\n",
      "('harpercollins', 1.8927034055101044)\n",
      "('alafair', 1.8753738127073951)\n",
      "('dany', 1.853341642609548)\n",
      "('gitomer', 1.8495983741606035)\n",
      "('septimus', 1.8426698293836294)\n",
      "('refreshingly', 1.8256662774658516)\n",
      "('renni', 1.8256196890411347)\n",
      "('quibbles', 1.8232014639190295)\n",
      "('postsecret', 1.8142724698162946)\n",
      "('toole', 1.8101828847793728)\n",
      "('coetzee', 1.8059968158101514)\n",
      "('bravo', 1.8022502455206304)\n",
      "('baudelaires', 1.7924734060576915)\n",
      "('crownover', 1.7792581644463012)\n",
      "('kerrelyn', 1.7752349962199256)\n",
      "('lippman', 1.7702892073896135)\n",
      "('bukowski', 1.7702828808908073)\n",
      "('biscuit', 1.7642307291116026)\n",
      "('lashner', 1.7613649998571577)\n",
      "('chinaski', 1.7582105243697648)\n",
      "('boortz', 1.757610453737932)\n",
      "('sobering', 1.738749849723417)\n",
      "('wiesels', 1.738213984430764)\n",
      "('fayz', 1.7236276224091018)\n",
      "('borgs', 1.720844839667965)\n",
      "('unearthly', 1.7198874849355852)\n",
      "('schaums', 1.7194643171819914)\n",
      "('sandman', 1.7080543125069518)\n",
      "('lurie', 1.7005045356364317)\n",
      "('crombie', 1.7004168826607273)\n",
      "('sabriel', 1.6944459183986786)\n",
      "('punches', 1.6943694122823385)\n",
      "('getabstract', 1.6854660634062675)\n",
      "('langoliers', 1.6807966851407454)\n",
      "('enzo', 1.6794405037114941)\n",
      "('meena', 1.677953036723321)\n",
      "('hoffer', 1.67035186614164)\n",
      "('eloisa', 1.6646399625268233)\n",
      "('vail', 1.6577007812816127)\n",
      "('weggins', 1.6556926071337525)\n",
      "('grippando', 1.6528688103173699)\n",
      "('jacinda', 1.6528408140845707)\n",
      "('stossels', 1.6495004084030132)\n",
      "('murakami', 1.6471635333388226)\n",
      "('lorien', 1.6469885261042518)\n",
      "('patchett', 1.6463721422084163)\n",
      "('disappoint', 1.6459043703512062)\n",
      "('caylee', 1.6395650970823101)\n",
      "('ranney', 1.633437034608241)\n",
      "('bourdain', 1.6310668157043604)\n",
      "('hurston', 1.6292060154448584)\n",
      "('angstrom', 1.6288251961099423)\n",
      "('apprehensive', 1.6282111464787041)\n",
      "('jenkins', 1.6210970802007953)\n",
      "('mckee', 1.6204577354256626)\n",
      "('shepard', 1.620051258555359)\n",
      "('lyssa', 1.619845199675981)\n",
      "('ree', 1.6169237285869014)\n",
      "('stegner', 1.5961163892147088)\n",
      "('maupin', 1.5935904009303177)\n",
      "('monogamy', 1.586902094174137)\n",
      "('quotdeep', 1.5854281869751947)\n",
      "('janelle', 1.5834596445010016)\n",
      "('steinbeck', 1.571791191521653)\n",
      "('pitera', 1.5702185767912296)\n",
      "('sugarcreek', 1.5656044289003255)\n",
      "('karr', 1.5648912393736727)\n",
      "('carmack', 1.5621101760713454)\n",
      "('naysayers', 1.5590933233160071)\n",
      "('fuhrman', 1.5572814812130658)\n",
      "('carraway', 1.556891815430641)\n",
      "('schlosser', 1.5556329139143952)\n",
      "('jeaniene', 1.5550846897522643)\n",
      "('discworld', 1.5510588188390733)\n",
      "('guhrke', 1.5501867770639557)\n",
      "('shriver', 1.547848792980507)\n",
      "('jinni', 1.5426831171476483)\n",
      "('vermeers', 1.5366555100902748)\n",
      "('kingsolver', 1.5348464181092278)\n",
      "('spongs', 1.5322801786132378)\n",
      "('annabelle', 1.5309811066840067)\n",
      "('sigma', 1.53042571149134)\n",
      "('complaint', 1.530387684673951)\n",
      "('langella', 1.5292112840563008)\n",
      "('allon', 1.52825271649736)\n",
      "('roarks', 1.5260318441123084)\n",
      "('addicting', 1.5231794530787437)\n",
      "('soma', 1.5228988787802888)\n",
      "('gatsbys', 1.5221156606088444)\n",
      "('hodel', 1.5215166477623883)\n",
      "('flashman', 1.521340618501774)\n",
      "('delightfully', 1.5194045754346468)\n",
      "('gutman', 1.5189480435083114)\n"
     ]
    }
   ],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:120]:\n",
    "    print (best_positive)\n",
    "\n",
    "writers = ['klausner','rollins','ehrman','gaiman','spong','olaf','steinbeck','harpercollins','discworld',\n",
    "'kingsolver','pratchett','maxon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T12:07:17.875433Z",
     "start_time": "2019-04-08T12:07:17.822327Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    \n",
    "    random.shuffle(reviews_lst_good)\n",
    "    random.shuffle(reviews_lst_bad)\n",
    "                    \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "    for i in reviews_lst_good:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    for i in reviews_lst_bad:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "    df['reviewerID'] = reviewerID_lst\n",
    "    # df['reviewerName'] = reviewerName_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "    df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = CountVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    \n",
    "    for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "        lr = LogisticRegression(C=c)\n",
    "        lr.fit(X_train, y_train)\n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "    \n",
    "    final_model = LogisticRegression(C=parametr)\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T13:21:07.933762Z",
     "start_time": "2019-04-08T12:10:53.217970Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Health_and_Personal_Care_5.json\n",
      "Accuracy for C=0.01: 0.9375511763742562\n",
      "Accuracy for C=0.05: 0.94242316720345\n",
      "Accuracy for C=0.25: 0.9450161034990993\n",
      "Accuracy for C=0.5: 0.9445930454719144\n",
      "Accuracy for C=1: 0.9438561056826246\n",
      "Final Accuracy: 0.73015\n",
      "('deducted', 1.7656824591106735)\n",
      "('pleasantly', 1.656820137862464)\n",
      "('pleased', 1.6369400592065257)\n",
      "('skeptical', 1.5956846843153587)\n",
      "('highly', 1.5722485210054)\n",
      "('disappointing', -2.5610881508681285)\n",
      "('worthless', -2.4379621815169608)\n",
      "('disappointment', -2.143615023529117)\n",
      "('unacceptable', -2.0601684486255207)\n",
      "('poorly', -1.905376850288279)\n",
      "Movies_and_TV_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Movies_and_TV_5.json\n",
      "Accuracy for C=0.01: 0.907810879772571\n",
      "Accuracy for C=0.05: 0.9136597187430822\n",
      "Accuracy for C=0.25: 0.9151918349275886\n",
      "Accuracy for C=0.5: 0.914830651644549\n",
      "Accuracy for C=1: 0.9139975998788288\n",
      "Final Accuracy: 0.88745\n",
      "('coulardeau', 2.4949225480924606)\n",
      "('quotable', 2.027263219530878)\n",
      "('crunches', 1.7436805584481667)\n",
      "('coz', 1.6879254905129906)\n",
      "('pleasantly', 1.6870842185236206)\n",
      "('kgharris', -2.3544545139492)\n",
      "('waste', -2.191112258674876)\n",
      "('promisingly', -2.1100479690920535)\n",
      "('snoozer', -2.081385107516871)\n",
      "('poorest', -2.05147707247044)\n",
      "Electronics_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Electronics_5.json\n",
      "Accuracy for C=0.01: 0.9043925183493623\n",
      "Accuracy for C=0.05: 0.9098719867395673\n",
      "Accuracy for C=0.25: 0.9117799626752208\n",
      "Accuracy for C=0.5: 0.9117680378256229\n",
      "Accuracy for C=1: 0.9107603880346059\n",
      "Final Accuracy: 0.8743\n",
      "('boxwave', 2.3682048593681566)\n",
      "('squaretrade', 2.2378293628584087)\n",
      "('hesitate', 1.9407943708425313)\n",
      "('itorch', 1.8752622232069476)\n",
      "('stumbled', 1.8445148456758234)\n",
      "('unacceptable', -2.6860947403398256)\n",
      "('paperweight', -2.3778730286427594)\n",
      "('disappointing', -2.2333105750540048)\n",
      "('returning', -2.1740437708106772)\n",
      "('loser', -2.0978861388503933)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.5)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T04:59:50.356600Z",
     "start_time": "2019-04-08T13:24:25.357659Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Health_and_Personal_Care_5.json\n",
      "Accuracy for C=0.01: 0.9362683552595665\n",
      "Accuracy for C=0.05: 0.9409765816911404\n",
      "Accuracy for C=0.25: 0.9428871663300399\n",
      "Accuracy for C=0.5: 0.94253234346853\n",
      "Accuracy for C=1: 0.9417408155467002\n",
      "Final Accuracy: 0.72545\n",
      "('pleased', 1.5682731570972217)\n",
      "('hesitate', 1.5175314175031036)\n",
      "('glad', 1.450800831389244)\n",
      "('excellent', 1.4128644601444649)\n",
      "('complaints', 1.4126178401834528)\n",
      "('disappointing', -2.2840623587693756)\n",
      "('worthless', -2.0835303820172033)\n",
      "('disappointment', -1.9798090638320425)\n",
      "('useless', -1.8005429485885187)\n",
      "('unacceptable', -1.6859019789724752)\n",
      "Movies_and_TV_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Movies_and_TV_5.json\n",
      "Accuracy for C=0.01: 0.907810879772571\n",
      "Accuracy for C=0.05: 0.9135315569329714\n",
      "Accuracy for C=0.25: 0.9153025201272297\n",
      "Accuracy for C=0.5: 0.9148539537918419\n",
      "Accuracy for C=1: 0.9137529273322537\n",
      "Final Accuracy: 0.88665\n",
      "('coulardeau', 1.8589836201435477)\n",
      "('quotable', 1.5625762529066318)\n",
      "('complaint', 1.5431713939976195)\n",
      "('pleasantly', 1.5143552297441905)\n",
      "('coz', 1.4730948999070264)\n",
      "('waste', -2.1133926268928818)\n",
      "('stinks', -1.8596052008519843)\n",
      "('redeeming', -1.8589545343774403)\n",
      "('tedious', -1.842893907876198)\n",
      "('worst', -1.8333211897635229)\n",
      "Electronics_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Electronics_5.json\n",
      "Accuracy for C=0.01: 0.9037962758694706\n",
      "Accuracy for C=0.05: 0.9093472933572625\n",
      "Accuracy for C=0.25: 0.9111002462481442\n",
      "Accuracy for C=0.5: 0.9108796365305842\n",
      "Accuracy for C=1: 0.9103668679978774\n",
      "Final Accuracy: 0.873\n",
      "('squaretrade', 1.9297052367779832)\n",
      "('boxwave', 1.8641636820709804)\n",
      "('hesitate', 1.768158563818394)\n",
      "('beat', 1.7298449210271705)\n",
      "('pleasantly', 1.5934649546679747)\n",
      "('unacceptable', -2.508323004208815)\n",
      "('disappointing', -2.135626392042135)\n",
      "('paperweight', -2.1224875756624835)\n",
      "('returning', -2.0780310280588785)\n",
      "('returned', -1.9417618426111165)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.25)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T05:02:49.894577Z",
     "start_time": "2019-04-09T05:02:49.783512Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    reviews_lst_good = random.shuffle(reviews_lst_good)\n",
    "    reviews_lst_bad = random.shuffle(reviews_lst_bad)  \n",
    "    \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "    for i in reviews_lst_good:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    for i in reviews_lst_bad:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "    df['reviewerID'] = reviewerID_lst\n",
    "    # df['reviewerName'] = reviewerName_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "    df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = TfidfVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    print ('    ')\n",
    "    \n",
    "    for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "        lr = LogisticRegression(C=c)\n",
    "        lr.fit(X_train, y_train)\n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "    \n",
    "    final_model = LogisticRegression(C=parametr)\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T05:06:09.510388Z",
     "start_time": "2019-04-09T05:05:39.513390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5.json\n",
      "   \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d1b16b377210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'   '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mclassify_it\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'G:\\\\Мой диск\\\\Work\\\\Experiment\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'   '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-8853d10c0c9e>\u001b[0m in \u001b[0;36mclassify_it\u001b[1;34m(filename, parametr)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# reviews_lst [0]['overall']<5 #['asin']for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreviews_lst_good\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mreviewerID_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviewerID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mreviewText_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviewText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('   ')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.25)\n",
    "        gc.collect()\n",
    "        print ('   ')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T05:06:09.517465Z",
     "start_time": "2019-04-08T12:23:52.163Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "list = [20, 16, 10, 5];\n",
    "random.shuffle(list)\n",
    "print (\"Reshuffled list : \",  list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T05:06:09.525818Z",
     "start_time": "2019-04-08T12:23:53.755Z"
    }
   },
   "outputs": [],
   "source": [
    "# BackUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T05:06:09.534745Z",
     "start_time": "2019-04-08T12:23:54.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_json('Books_5.json')\n",
    "# import ijson\n",
    "# filename = \"Books_5.json\"\n",
    "# with open(filename, 'r') as f:\n",
    "#     objects = ijson.items(f, 'meta.view.columns.item')\n",
    "#     columns = list(objects)\n",
    "#     print (objects)\n",
    "# handle = open(\"Books_5.json\", \"r\")\n",
    "\n",
    "# while True:\n",
    "#     data = handle.read(20000)\n",
    "#     if not data:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "179.391px",
    "left": "1521px",
    "right": "20px",
    "top": "117px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
