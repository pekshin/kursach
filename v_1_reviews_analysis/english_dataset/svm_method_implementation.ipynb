{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gc\n",
    "import random\n",
    "i = 0\n",
    "reviews_lst_good= []\n",
    "reviews_lst_bad = []\n",
    "count_good_comments = 0\n",
    "count_bad_comments = 0\n",
    "\n",
    "\n",
    "with open('/Volumes/GoogleDrive/Мой диск/Work/Experiment/Books_5.json', 'r') as f: # указать свой путь\n",
    "        for line in f:\n",
    "            if json.loads(line)['overall'] > 3:\n",
    "                  count_good_comments += 1\n",
    "            elif json.loads(line)['overall'] < 3:\n",
    "                  count_bad_comments += 1\n",
    "            \n",
    "print (count_good_comments)\n",
    "print (count_bad_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_df = min (count_good_comments, count_bad_comments)\n",
    "print (size_of_df)\n",
    "\n",
    "with open('/Volumes/GoogleDrive/Мой диск/Work/Experiment/Books_5.json', 'r') as f:\n",
    "        for line in f:\n",
    "            if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=size_of_df:\n",
    "                reviews_lst_good.append (json.loads(line))\n",
    "            \n",
    "            elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=size_of_df:\n",
    "                reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "            if len(reviews_lst_good) + len (reviews_lst_bad) == 10000000:\n",
    "                break\n",
    "\n",
    "random.shuffle(reviews_lst_good)\n",
    "random.shuffle(reviews_lst_bad)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(reviews_lst_good))\n",
    "print (len(reviews_lst_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewerID_lst = []\n",
    "reviewerName_lst = []\n",
    "reviewText_lst = []\n",
    "overall_lst = []\n",
    "summary_lst = []\n",
    "\n",
    "# reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "for i in reviews_lst_good:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "for i in reviews_lst_bad:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "df = pd.DataFrame ()\n",
    "\n",
    "df['reviewerID'] = reviewerID_lst\n",
    "# df['reviewerName'] = reviewerName_lst\n",
    "df['reviewText'] = reviewText_lst\n",
    "df['overall'] = overall_lst\n",
    "df['summary'] = summary_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df ['mark'] = -1\n",
    "df.loc[df['overall'] > 3,'mark'] = 1\n",
    "\n",
    "print (len(df[df['mark'] > 0]))\n",
    "print (len(df[df['mark'] < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['mark'] != 0)&(df['mark'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer() # создали генератор признаков \n",
    "\n",
    "vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "\n",
    "cv = KFold(5, shuffle=True, random_state=241) # делим на 5 блоков\n",
    "\n",
    "model = SVC(kernel='linear', random_state=241) # устанавливаем линейной ядро у SVM\n",
    "\n",
    "gs = GridSearchCV(model, grid, scoring='accuracy', cv=cv) # показываем, чтобы использовал модель нашу \n",
    "# + искал параметр C сам из диапозона, метод для валивации KFold\n",
    "\n",
    "gs.fit(vectorizer.transform(X), y)\n",
    "\n",
    "\n",
    "\n",
    "C = gs.best_params_.get('C') # достаём оттуда только C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Обучите SVM по всей выборке с оптимальным параметром C, найденным на предыдущем шаге.\n",
    "\n",
    "\n",
    "\n",
    "model = SVC(kernel='linear', random_state=241, C=C)\n",
    "\n",
    "model.fit(vectorizer.transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Найдите 10 слов с наибольшим по модулю весом. Они являются ответом на это задание. Укажите их через запятую или\n",
    "\n",
    "# пробел, в нижнем регистре, в лексикографическом порядке.\n",
    "\n",
    "\n",
    "\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "coef = pd.DataFrame(model.coef_.data, model.coef_.indices)\n",
    "\n",
    "top_words = coef[0].map(lambda w: abs(w)).sort_values(ascending=False).head(10).index.map(lambda i: words[i])\n",
    "\n",
    "top_words.sort_values ()\n",
    "\n",
    "# top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
