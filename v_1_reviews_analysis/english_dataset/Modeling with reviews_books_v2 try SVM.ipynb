{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:46:44.631691Z",
     "start_time": "2019-04-21T09:46:44.628344Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gengo.ai/datasets/15-free-sentiment-analysis-datasets-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:49:31.709058Z",
     "start_time": "2019-04-21T09:46:45.352508Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "i = 0\n",
    "reviews_lst_good= []\n",
    "reviews_lst_bad = []\n",
    "\n",
    "\n",
    "with open('/Volumes/GoogleDrive/Мой диск/Work/Experiment/Books_5.json', 'r') as f: # C:\\\\Users\\\\denis.pekhterev\\\\Downloads\\\\Experiment_old\\\\Books_5.json\n",
    "        for line in f:\n",
    "            if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                reviews_lst_good.append (json.loads(line))\n",
    "            \n",
    "            elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "            if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                break\n",
    "                \n",
    "random.shuffle(reviews_lst_good)\n",
    "random.shuffle(reviews_lst_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:50:09.551333Z",
     "start_time": "2019-04-21T09:50:06.058703Z"
    }
   },
   "outputs": [],
   "source": [
    "reviewerID_lst = []\n",
    "reviewerName_lst = []\n",
    "reviewText_lst = []\n",
    "overall_lst = []\n",
    "summary_lst = []\n",
    "\n",
    "# reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "for i in reviews_lst_good:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "for i in reviews_lst_bad:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "df = pd.DataFrame ()\n",
    "\n",
    "df['reviewerID'] = reviewerID_lst\n",
    "# df['reviewerName'] = reviewerName_lst\n",
    "df['reviewText'] = reviewText_lst\n",
    "df['overall'] = overall_lst\n",
    "df['summary'] = summary_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:50:50.932280Z",
     "start_time": "2019-04-21T09:50:49.841373Z"
    }
   },
   "outputs": [],
   "source": [
    "df ['mark'] = 0\n",
    "df.loc[df['overall'] > 3,'mark'] = 1\n",
    "\n",
    "print (len(df[df['mark'] > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:51:28.352502Z",
     "start_time": "2019-04-21T09:51:28.321247Z"
    }
   },
   "outputs": [],
   "source": [
    "df[(df['mark'] != 0)&(df['mark'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:52:06.725543Z",
     "start_time": "2019-04-21T09:52:05.893071Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:52:57.109585Z",
     "start_time": "2019-04-21T09:52:57.101448Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(df[df['overall'] > 3]['reviewText'][:2])\n",
    "reviews_train [:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:55:05.255546Z",
     "start_time": "2019-04-21T09:53:49.324282Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:02:04.897735Z",
     "start_time": "2019-04-21T09:56:13.721756Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:03:20.714791Z",
     "start_time": "2019-04-21T09:58:52.165Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:03:20.723786Z",
     "start_time": "2019-04-21T09:58:52.600Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = LogisticRegression(C=0.5)\n",
    "final_model.fit(X,  y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                        , final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:11:22.581790Z",
     "start_time": "2019-04-21T10:10:12.022Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c_dict = {}\n",
    "\n",
    "best_c_dict ['c'+str(1)] = 25\n",
    "best_c_dict ['c'+str(2)] = 35\n",
    "\n",
    "inverse = [(value, key) for key, value in best_c_dict.items()]\n",
    "print (max(inverse)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:14:28.843384Z",
     "start_time": "2019-04-21T10:14:28.809700Z"
    }
   },
   "outputs": [],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:11:22.598293Z",
     "start_time": "2019-04-21T10:10:13.292Z"
    }
   },
   "outputs": [],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:120]:\n",
    "    print (best_positive)\n",
    "\n",
    "writers = ['klausner','rollins','ehrman','gaiman','spong','olaf','steinbeck','harpercollins','discworld',\n",
    "'kingsolver','pratchett','maxon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best of my variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:50.132Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    random.shuffle(reviews_lst_good)\n",
    "    random.shuffle(reviews_lst_bad)  \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "    for i in reviews_lst_good:\n",
    "#         reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "#         summary_lst.append (i['summary'])\n",
    "\n",
    "    for i in reviews_lst_bad:\n",
    "#         reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "#         summary_lst.append (i['summary'])\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "#     df['reviewerID'] = reviewerID_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "#     df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = TfidfVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    print ('    ')\n",
    "    \n",
    "    \n",
    "    best_c_dict = {}\n",
    "\n",
    "    \n",
    "    \n",
    "    for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "        lr = SVC(kernel='linear', random_state=241, C=c)\n",
    "        lr.fit(X_train, y_train)\n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "        best_c_dict ['c'+str(c)] = accuracy_score(y_val, lr.predict(X_val)) \n",
    "    \n",
    "    inverse = [(value, key) for key, value in best_c_dict.items()]\n",
    "    print (max(inverse)[1])\n",
    "\n",
    "    final_model = LogisticRegression(C=best_c_dict[max(inverse)[1]])\n",
    "    print ('Model use C = ', best_c_dict[max(inverse)[1]])\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:51.011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5.json\n",
      "   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбор параметра для:  /Volumes/GoogleDrive/Мой диск/Work/Experiment/Health_and_Personal_Care_5.json\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('/Volumes/GoogleDrive/Мой диск/Work/Experiment')\n",
    "\n",
    "for i in os.listdir('/Volumes/GoogleDrive/Мой диск/Work/Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints' and i != 'Books_5.json':\n",
    "        print (i)\n",
    "        print ('   ')\n",
    "        classify_it ('/Volumes/GoogleDrive/Мой диск/Work/Experiment/' + i, 0.25)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:53.755Z"
    }
   },
   "outputs": [],
   "source": [
    "# BackUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:54.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_json('Books_5.json')\n",
    "# import ijson\n",
    "# filename = \"Books_5.json\"\n",
    "# with open(filename, 'r') as f:\n",
    "#     objects = ijson.items(f, 'meta.view.columns.item')\n",
    "#     columns = list(objects)\n",
    "#     print (objects)\n",
    "# handle = open(\"Books_5.json\", \"r\")\n",
    "\n",
    "# while True:\n",
    "#     data = handle.read(20000)\n",
    "#     if not data:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "179.391px",
    "left": "1521px",
    "right": "20px",
    "top": "117px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
