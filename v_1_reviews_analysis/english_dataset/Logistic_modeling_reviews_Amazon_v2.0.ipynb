{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T19:53:52.948081Z",
     "start_time": "2019-05-20T19:53:52.938138Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T19:53:52.960619Z",
     "start_time": "2019-05-20T19:53:52.952245Z"
    }
   },
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T19:53:53.006361Z",
     "start_time": "2019-05-20T19:53:52.966113Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    # random elements in the list\n",
    "    random.shuffle(reviews_lst_good)\n",
    "    random.shuffle(reviews_lst_bad)  \n",
    "    \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "    \n",
    "    if len (reviews_lst_bad) < len(reviews_lst_good):\n",
    "        count_otz = len (reviews_lst_bad)\n",
    "    else:\n",
    "        count_otz = len (reviews_lst_good)\n",
    "\n",
    "    for i in reviews_lst_good[:count_otz]:\n",
    "#         reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "#         summary_lst.append (i['summary'])\n",
    "\n",
    "    print ('Good: ',len(reviews_lst_good[:count_otz]))\n",
    "\n",
    "    for i in reviews_lst_bad[:count_otz]:\n",
    "#         reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "#         summary_lst.append (i['summary'])\n",
    "\n",
    "    print ('Bad: ',len(reviews_lst_bad[:count_otz]))\n",
    "    \n",
    "    test_len = int(round (len(reviews_lst_bad[:count_otz])*0.1,0))\n",
    "    \n",
    "    print ('10%: ',test_len)\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "#     df['reviewerID'] = reviewerID_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "#     df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    # \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-test_len]) + list(df[df['overall'] < 3]['reviewText'][:-test_len])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-test_len:]) + list(df[df['overall'] < 3]['reviewText'][-test_len:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = TfidfVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-test_len]) + list(df[df['overall'] < 3]['mark'][:-test_len])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    print ('    ')\n",
    "    \n",
    "    \n",
    "    best_c_dict = {}\n",
    "    main_dict = {}\n",
    "    c_list = []\n",
    "    result_1_list = []\n",
    "    result_2_list = []\n",
    "    \n",
    "    grid = np.power(10.0, np.arange(-4, 4))\n",
    "    \n",
    "    for c in grid:\n",
    "        lr = LogisticRegression(C=c)\n",
    "        lr.fit(X_train, y_train)\n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "        \n",
    "        c_list.append (c)\n",
    "        result_1_list.append (accuracy_score(y_val, lr.predict(X_val)))\n",
    "        result_2_list.append (accuracy_score(list(df[df['overall'] > 3]['mark'][-test_len:]) + list(df[df['overall'] < 3]['mark'][-test_len:])\n",
    "                            ,lr.predict(X_test)))\n",
    "        \n",
    "        \n",
    "        best_c_dict [c] = accuracy_score(y_val, lr.predict(X_val))\n",
    "        main_dict [c] = [filename, accuracy_score(y_val, lr.predict(X_val))]\n",
    "        \n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    result['c'] = c_list\n",
    "    result ['result_1'] = result_1_list\n",
    "    result ['result_2'] = result_2_list\n",
    "    \n",
    "    result.to_csv (filename+'_c.csv', index=False)\n",
    "    \n",
    "    inverse = [(value, key) for key, value in best_c_dict.items()]\n",
    "    print (max(inverse)[1])\n",
    "\n",
    "    final_model = LogisticRegression(C=best_c_dict[max(inverse)[1]])\n",
    "    print ('Model use C = ', best_c_dict[max(inverse)[1]])\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score(list(df[df['overall'] > 3]['mark'][-test_len:]) + list(df[df['overall'] < 3]['mark'][-test_len:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad\n",
    "    \n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T20:59:55.042720Z",
     "start_time": "2019-05-20T19:53:53.008888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies_and_TV_5.json\n",
      "   \n",
      "Good:  206629\n",
      "Bad:  206629\n",
      "10%:  20663\n",
      "Подбор параметра для:  /Volumes/GoogleDrive/Мой диск/Work/Experiment/Movies_and_TV_5.json\n",
      "    \n",
      "Accuracy for C=0.0001: 0.818880870696794\n",
      "Accuracy for C=0.001: 0.8325930546443974\n",
      "Accuracy for C=0.01: 0.8619102416570771\n",
      "Accuracy for C=0.1: 0.8909585623178431\n",
      "Accuracy for C=1.0: 0.904799802114365\n",
      "Accuracy for C=10.0: 0.9044126345676091\n",
      "Accuracy for C=100.0: 0.8896572491745803\n",
      "Accuracy for C=1000.0: 0.8662443672499274\n",
      "1.0\n",
      "Model use C =  0.904799802114365\n",
      "Final Accuracy: 0.9028456661665779\n",
      "('great', 11.48366853602865)\n",
      "('excellent', 9.465355195067756)\n",
      "('perfect', 8.798729125962183)\n",
      "('superb', 7.946345800065548)\n",
      "('best', 7.805905382566028)\n",
      "('worst', -14.723813069520524)\n",
      "('waste', -13.884366717862207)\n",
      "('boring', -12.924290235141054)\n",
      "('not', -10.369562128273216)\n",
      "('terrible', -9.97326181176191)\n",
      "Electronics_5.json\n",
      "   \n",
      "Good:  190864\n",
      "Bad:  190864\n",
      "10%:  19086\n",
      "Подбор параметра для:  /Volumes/GoogleDrive/Мой диск/Work/Experiment/Electronics_5.json\n",
      "    \n",
      "Accuracy for C=0.0001: 0.8257052707564414\n",
      "Accuracy for C=0.001: 0.8336341091408679\n",
      "Accuracy for C=0.01: 0.8614490796260289\n",
      "Accuracy for C=0.1: 0.8855848828138644\n",
      "Accuracy for C=1.0: 0.8966805993782673\n",
      "Accuracy for C=10.0: 0.8952834472400424\n",
      "Accuracy for C=100.0: 0.8819988589924205\n",
      "Accuracy for C=1000.0: 0.8585616318736975\n",
      "1.0\n",
      "Model use C =  0.8966805993782673\n",
      "Final Accuracy: 0.8983810122602955\n",
      "('great', 12.787981404204485)\n",
      "('excellent', 9.412008451431596)\n",
      "('perfect', 8.894698714846289)\n",
      "('highly', 8.537841294531434)\n",
      "('love', 8.01868475285947)\n",
      "('not', -13.959683212459565)\n",
      "('returned', -12.698520550640634)\n",
      "('return', -12.588277249653485)\n",
      "('returning', -12.102628870248239)\n",
      "('poor', -10.630256266094246)\n",
      "Books_5.json\n",
      "   \n",
      "Good:  499999\n",
      "Bad:  499999\n",
      "10%:  50000\n",
      "Подбор параметра для:  /Volumes/GoogleDrive/Мой диск/Work/Experiment/Books_5.json\n",
      "    \n",
      "Accuracy for C=0.0001: 0.8254622222222222\n",
      "Accuracy for C=0.001: 0.8427911111111112\n",
      "Accuracy for C=0.01: 0.8762177777777778\n",
      "Accuracy for C=0.1: 0.8990488888888889\n",
      "Accuracy for C=1.0: 0.9116266666666667\n",
      "Accuracy for C=10.0: 0.9132444444444444\n",
      "Accuracy for C=100.0: 0.9037688888888888\n",
      "Accuracy for C=1000.0: 0.88132\n",
      "10.0\n",
      "Model use C =  0.9132444444444444\n",
      "Final Accuracy: 0.9123\n",
      "('klausner', 9.690864877967005)\n",
      "('great', 9.674325713775172)\n",
      "('excellent', 9.371474386171002)\n",
      "('refreshing', 9.096276886997211)\n",
      "('enjoyed', 8.632844077666663)\n",
      "('waste', -12.881729117185786)\n",
      "('not', -12.649924231408542)\n",
      "('disappointing', -12.640154222723977)\n",
      "('boring', -12.213580928593743)\n",
      "('poorly', -11.83066712385993)\n",
      "reviews_Kindle_Store_5.json\n",
      "   \n",
      "Good:  57148\n",
      "Bad:  57148\n",
      "10%:  5715\n",
      "Подбор параметра для:  /Volumes/GoogleDrive/Мой диск/Work/Experiment/reviews_Kindle_Store_5.json\n",
      "    \n",
      "Accuracy for C=0.0001: 0.8028152583893923\n",
      "Accuracy for C=0.001: 0.8759575378154528\n",
      "Accuracy for C=0.01: 0.8880118209744527\n",
      "Accuracy for C=0.1: 0.907726406657075\n",
      "Accuracy for C=1.0: 0.919158533265933\n",
      "Accuracy for C=10.0: 0.9172531788311233\n",
      "Accuracy for C=100.0: 0.8991328693082397\n",
      "Accuracy for C=1000.0: 0.8721857137302174\n",
      "1.0\n",
      "Model use C =  0.919158533265933\n",
      "Final Accuracy: 0.9193350831146107\n",
      "('loved', 10.428521840880084)\n",
      "('great', 9.85193656945709)\n",
      "('enjoyed', 9.672770361429098)\n",
      "('wait', 8.600790103504332)\n",
      "('fun', 6.793135240318683)\n",
      "('not', -12.458629939703435)\n",
      "('waste', -8.715444470062717)\n",
      "('boring', -7.560092572882453)\n",
      "('potential', -6.775664907795286)\n",
      "('nothing', -6.72150118058067)\n",
      "reviews_CDs_and_Vinyl_5.json\n",
      "   \n",
      "Good:  92766\n",
      "Bad:  92766\n",
      "10%:  9277\n",
      "Подбор параметра для:  /Volumes/GoogleDrive/Мой диск/Work/Experiment/reviews_CDs_and_Vinyl_5.json\n",
      "    \n",
      "Accuracy for C=0.0001: 0.831069589172356\n",
      "Accuracy for C=0.001: 0.8341118696849922\n",
      "Accuracy for C=0.01: 0.8504731105521619\n",
      "Accuracy for C=0.1: 0.8782129596358845\n",
      "Accuracy for C=1.0: 0.8951251646903821\n",
      "Accuracy for C=10.0: 0.8951012097257156\n",
      "Accuracy for C=100.0: 0.881207330219188\n",
      "Accuracy for C=1000.0: 0.8635046113306983\n",
      "1.0\n",
      "Model use C =  0.8951251646903821\n",
      "Final Accuracy: 0.8929071898242966\n",
      "('great', 10.55933242408249)\n",
      "('best', 8.710397698455175)\n",
      "('favorite', 8.37276716474334)\n",
      "('perfect', 7.862334546114957)\n",
      "('favorites', 7.379452825725971)\n",
      "('worst', -13.510496780126454)\n",
      "('boring', -11.56748955281549)\n",
      "('awful', -9.734249383116222)\n",
      "('disappointing', -9.148166270152698)\n",
      "('terrible', -9.131930046166685)\n",
      "Icon\n",
      "   \n",
      "Good:  0\n",
      "Bad:  0\n",
      "10%:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ef26374f96d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'   '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdict_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_it\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/GoogleDrive/Мой диск/Work/Experiment/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-05afb5806c9a>\u001b[0m in \u001b[0;36mclassify_it\u001b[0;34m(filename, parametr)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_train_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_train_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_test_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1590\u001b[0m         \"\"\"\n\u001b[1;32m   1591\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1031\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    963\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('/Volumes/GoogleDrive/Мой диск/Work/Experiment')\n",
    "\n",
    "for i in os.listdir('/Volumes/GoogleDrive/Мой диск/Work/Experiment'):\n",
    "    if i[-5:] != 'ipynb'and i[-3:] != 'csv' and i != '.ipynb_checkpoints' and i != 'Health_and_Personal_Care_5.json':\n",
    "        print (i)\n",
    "        print ('   ')\n",
    "        dict_main = classify_it ('/Volumes/GoogleDrive/Мой диск/Work/Experiment/' + i, 0.25)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T20:59:55.053940Z",
     "start_time": "2019-05-20T19:53:52.927Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_lst = []\n",
    "y_lst = []\n",
    "for i in dict_main:\n",
    "    x_lst.append(i)\n",
    "    y_lst.append(dict_main[i][1])\n",
    "\n",
    "plt.bar(x_lst, y_lst, align='center', alpha=0.3, width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T20:59:55.057548Z",
     "start_time": "2019-05-20T19:53:52.935Z"
    }
   },
   "outputs": [],
   "source": [
    "np.power(10.0, np.arange(-5, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments\n",
    "\n",
    "https://habr.com/ru/company/ods/blog/323890/#1-lineynaya-regressiya\n",
    "\n",
    "https://docplayer.ru/28834116-Otchet-po-zadaniyu-4-issledovanie-modeli-logistic-regression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "\n",
    "http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_(%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9,_%D0%9A.%D0%92.%D0%92%D0%BE%D1%80%D0%BE%D0%BD%D1%86%D0%BE%D0%B2)#.D0.9E.D1.81.D0.BD.D0.BE.D0.B2.D0.BD.D1.8B.D0.B5_.D0.BF.D0.BE.D0.BD.D1.8F.D1.82.D0.B8.D1.8F_.D0.B8_.D0.BF.D1.80.D0.B8.D0.BC.D0.B5.D1.80.D1.8B_.D0.BF.D1.80.D0.B8.D0.BA.D0.BB.D0.B0.D0.B4.D0.BD.D1.8B.D1.85_.D0.B7.D0.B0.D0.B4.D0.B0.D1.87\n",
    "\n",
    "\n",
    "\n",
    "ROC:\n",
    "https://basegroup.ru/community/articles/logistic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
