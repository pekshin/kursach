{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:40:07.390467Z",
     "start_time": "2019-05-24T17:40:01.579590Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "######## METRICS\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "# matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# other\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:40:08.590412Z",
     "start_time": "2019-05-24T17:40:08.585347Z"
    }
   },
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:41:08.968478Z",
     "start_time": "2019-05-24T17:41:08.947752Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(filename):\n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "    #набираем список хороших/плохих отзывов, не более 75000 в каждом из списков\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=75000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=75000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 150000:\n",
    "                    break\n",
    "    \n",
    "    # перемешиваем список (внутри элементы одного класса)\n",
    "    random.shuffle(reviews_lst_good)\n",
    "    random.shuffle(reviews_lst_bad)  \n",
    "    \n",
    "    # создаём template для сохранения конечных отзывов\n",
    "    reviewText_lst = []\n",
    "    mark_lst = []\n",
    "    \n",
    "    \n",
    "    # где будем уменьшать количество отзывов, чтобы их было равное количество\n",
    "    if len (reviews_lst_bad) < len(reviews_lst_good):\n",
    "        count_otz = len (reviews_lst_bad)\n",
    "    else:\n",
    "        count_otz = len (reviews_lst_good)\n",
    "        \n",
    "    \n",
    "    # i -- это СЛОВАРЬ!        \n",
    "    # обрезаем хороший и наполняем уже итоговый список\n",
    "    for i in reviews_lst_good[:count_otz]:\n",
    "        reviewText_lst.append (i['reviewText'])    \n",
    "        mark_lst.append (1)\n",
    "    print ('Good: ',len(reviews_lst_good[:count_otz]))\n",
    "\n",
    "    # обрезаем плохие\n",
    "    for i in reviews_lst_bad[:count_otz]:\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        mark_lst.append (-1)\n",
    "    print ('Bad: ',len(reviews_lst_bad[:count_otz]))\n",
    "\n",
    "    return reviewText_lst, mark_lst\n",
    "    \n",
    "def classify_it(filename, reviewText_lst, mark_lst):  \n",
    "    \n",
    "    # выборки готовы к передачи в модель\n",
    "    reviews_train = reviewText_lst\n",
    "    y = mark_lst\n",
    "    \n",
    "    # очищаем отзывы от лишних символов\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    \n",
    "    \n",
    "    # делим выборку на тестовую и обучающую\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        reviews_train_clean, y, train_size = 0.75\n",
    "    )  \n",
    "    \n",
    "    # столбец ответов \n",
    "    \n",
    "\n",
    "    print ('Подбор параметра для: ', filename[:-5])\n",
    "    print ('    ')\n",
    "    best_c_dict = {} # модель сама ищет лучший c и его результаты подбирает в итоге\n",
    "    c_list = []\n",
    "    result_c_list = []      \n",
    "   \n",
    "    time_lst_fit = []\n",
    "    time_frcst_lst = []\n",
    "    result_time_fit_lst = []\n",
    "    result_time_frcst_lst = []\n",
    "    \n",
    "    # определяем, где алгоритму необходимо искать С\n",
    "    grid = [0.01,0.1,1,10]\n",
    "    \n",
    "    \n",
    "    print ('Бинаризируем столбец признаков')\n",
    "    # бинаризируем столбец признаков\n",
    "    cv = TfidfVectorizer(min_df=10, decode_error='replace', encoding='utf-8')\n",
    "    X = cv.fit_transform(X_train)\n",
    "    X_test = cv.transform(X_val)\n",
    "    \n",
    "#    X = preprocessing.scale(X,with_mean=False)\n",
    "#    X_test = preprocessing.scale(X_test,with_mean=False)\n",
    "    \n",
    "    print ('c подбираем')\n",
    "\n",
    "    \n",
    "    # итерируемся и подбираем параметр, используя Accuracy\n",
    "    for c in grid:\n",
    "        \n",
    "        final_model = svm.SVC(kernel='linear', C=c, decision_function_shape='ovo')\n",
    "        \n",
    "        startTime = time.time()\n",
    "        final_model.fit(X, y_train) ######\n",
    "        resultTime = time.time() - startTime\n",
    "        time_lst_fit.append (resultTime)\n",
    "        \n",
    "        startTime = time.time()\n",
    "        y_pred = final_model.predict(X_test) #####\n",
    "        resultTime = time.time() - startTime\n",
    "        time_frcst_lst.append (resultTime)\n",
    "        \n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, y_pred)))\n",
    "        \n",
    "        c_list.append (c)\n",
    "        result_c_list.append (accuracy_score(y_val, y_pred))\n",
    "        best_c_dict [c] = accuracy_score(y_val, y_pred)\n",
    "        \n",
    "    \n",
    "    # записываем результаты подбора коэффициента c\n",
    "    result_с = pd.DataFrame()\n",
    "    result_с['c'] = c_list\n",
    "    result_с ['result_acc'] = result_c_list\n",
    "    result_с['fit_time'] = time_lst_fit\n",
    "    result_с['forecast_time'] = time_frcst_lst\n",
    "    result_с.to_csv (filename[:-5]+'_podbor_c_svm.csv', index=False)\n",
    "    ###########################################################################\n",
    "    \n",
    "    inverse = [(value, key) for key, value in best_c_dict.items()]\n",
    "    print ('The best C is ', max(inverse)[1])\n",
    "    \n",
    "    \n",
    "    ### строим предсказание с лучшим c ++ считаем потраченное время\n",
    "    final_model_last = svm.SVC(kernel='linear', C=max(inverse)[1], decision_function_shape='ovo')\n",
    "    final_model_last.fit(X, y_train)\n",
    "    y_pred_last = final_model.predict(X_test)\n",
    "    ################\n",
    "\n",
    "    # смотрим на метрики \n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score(y_val\n",
    "                            , y_pred_last))\n",
    "    \n",
    "    print('confusion_matrix')\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix = confusion_matrix(y_val, y_pred_last)\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    print ('classification_report')\n",
    "    print(classification_report(y_val, y_pred_last))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T20:02:13.979848Z",
     "start_time": "2019-05-24T17:41:10.312566Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5\n",
      "   \n",
      "Good:  33300\n",
      "Bad:  33300\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Health_and_Personal_Care_5\n",
      "    \n",
      "Бинаризируем столбец признаков\n",
      "c подбираем\n",
      "Accuracy for C=0.01: 0.8062462462462463\n",
      "Accuracy for C=0.1: 0.8561561561561561\n",
      "Accuracy for C=1: 0.8652252252252253\n",
      "Accuracy for C=10: 0.8506306306306306\n",
      "The best C is  1\n",
      "Final Accuracy: 0.8506306306306306\n",
      "confusion_matrix\n",
      "[[7102 1243]\n",
      " [1244 7061]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.85      0.85      8345\n",
      "           1       0.85      0.85      0.85      8305\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     16650\n",
      "   macro avg       0.85      0.85      0.85     16650\n",
      "weighted avg       0.85      0.85      0.85     16650\n",
      "\n",
      "Movies_and_TV_5\n",
      "   \n",
      "Good:  74999\n",
      "Bad:  74999\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Movies_and_TV_5\n",
      "    \n",
      "Бинаризируем столбец признаков\n",
      "c подбираем\n",
      "Accuracy for C=0.01: 0.85248\n",
      "Accuracy for C=0.1: 0.8966666666666666\n",
      "Accuracy for C=1: 0.9098933333333333\n",
      "Accuracy for C=10: 0.8968533333333333\n",
      "The best C is  1\n",
      "Final Accuracy: 0.8968533333333333\n",
      "confusion_matrix\n",
      "[[16689  2005]\n",
      " [ 1863 16943]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.89      0.90     18694\n",
      "           1       0.89      0.90      0.90     18806\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     37500\n",
      "   macro avg       0.90      0.90      0.90     37500\n",
      "weighted avg       0.90      0.90      0.90     37500\n",
      "\n",
      "Electronics_5\n",
      "   \n",
      "Good:  74999\n",
      "Bad:  74999\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Electronics_5\n",
      "    \n",
      "Бинаризируем столбец признаков\n",
      "c подбираем\n",
      "Accuracy for C=0.01: 0.8629066666666667\n",
      "Accuracy for C=0.1: 0.8968\n",
      "Accuracy for C=1: 0.9065066666666667\n",
      "Accuracy for C=10: 0.8970133333333333\n",
      "The best C is  1\n",
      "Final Accuracy: 0.8970133333333333\n",
      "confusion_matrix\n",
      "[[16927  1892]\n",
      " [ 1970 16711]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.90      0.90     18819\n",
      "           1       0.90      0.89      0.90     18681\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     37500\n",
      "   macro avg       0.90      0.90      0.90     37500\n",
      "weighted avg       0.90      0.90      0.90     37500\n",
      "\n",
      "Books_5\n",
      "   \n",
      "Good:  74999\n",
      "Bad:  74999\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Books_5\n",
      "    \n",
      "Бинаризируем столбец признаков\n",
      "c подбираем\n",
      "Accuracy for C=0.01: 0.8536266666666666\n",
      "Accuracy for C=0.1: 0.8974666666666666\n",
      "Accuracy for C=1: 0.9100533333333334\n",
      "Accuracy for C=10: 0.89856\n",
      "The best C is  1\n",
      "Final Accuracy: 0.89856\n",
      "confusion_matrix\n",
      "[[16906  1940]\n",
      " [ 1864 16790]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.90      0.90     18846\n",
      "           1       0.90      0.90      0.90     18654\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     37500\n",
      "   macro avg       0.90      0.90      0.90     37500\n",
      "weighted avg       0.90      0.90      0.90     37500\n",
      "\n",
      "reviews_Kindle_Store_5\n",
      "   \n",
      "Good:  57148\n",
      "Bad:  57148\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\reviews_Kindle_Store_5\n",
      "    \n",
      "Бинаризируем столбец признаков\n",
      "c подбираем\n",
      "Accuracy for C=0.01: 0.8879400853923147\n",
      "Accuracy for C=0.1: 0.9167424931756142\n",
      "Accuracy for C=1: 0.923216910478057\n",
      "Accuracy for C=10: 0.9109330160285575\n",
      "The best C is  1\n",
      "Final Accuracy: 0.9109330160285575\n",
      "confusion_matrix\n",
      "[[12979  1269]\n",
      " [ 1276 13050]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.91      0.91     14248\n",
      "           1       0.91      0.91      0.91     14326\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     28574\n",
      "   macro avg       0.91      0.91      0.91     28574\n",
      "weighted avg       0.91      0.91      0.91     28574\n",
      "\n",
      "reviews_CDs_and_Vinyl_5\n",
      "   \n",
      "Good:  74999\n",
      "Bad:  74999\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\reviews_CDs_and_Vinyl_5\n",
      "    \n",
      "Бинаризируем столбец признаков\n",
      "c подбираем\n",
      "Accuracy for C=0.01: 0.8574933333333333\n",
      "Accuracy for C=0.1: 0.90064\n",
      "Accuracy for C=1: 0.9122933333333333\n",
      "Accuracy for C=10: 0.8997066666666667\n",
      "The best C is  1\n",
      "Final Accuracy: 0.8997066666666667\n",
      "confusion_matrix\n",
      "[[16718  1887]\n",
      " [ 1874 17021]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.90      0.90     18605\n",
      "           1       0.90      0.90      0.90     18895\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     37500\n",
      "   macro avg       0.90      0.90      0.90     37500\n",
      "weighted avg       0.90      0.90      0.90     37500\n",
      "\n",
      "SVM Results\n",
      "   \n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x98 in position 759: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0cd2b73277e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'   '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_dataset\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'G:\\\\Мой диск\\\\Work\\\\Experiment\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mclassify_it\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'G:\\\\Мой диск\\\\Work\\\\Experiment\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-232fb9110b98>\u001b[0m in \u001b[0;36mprepare_dataset\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#набираем список хороших/плохих отзывов, не более 75000 в каждом из списков\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'overall'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_lst_good\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m75000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mreviews_lst_good\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1251.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x98 in position 759: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "# G:\\\\Мой диск\\\\Work\\\\Experiment\n",
    "#/Volumes/GoogleDrive/Мой диск/Work/Experiment\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb'and i[-3:] != 'csv' and i != '.ipynb_checkpoints': # and i == 'Health_and_Personal_Care_5.json':\n",
    "        print (i[:-5])\n",
    "        print ('   ')\n",
    "        x,y = prepare_dataset ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i)\n",
    "        \n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i,x,y)\n",
    "        \n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T05:28:13.828868Z",
     "start_time": "2019-05-24T05:28:13.665Z"
    }
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \": Main script Started\")\n",
    "\n",
    "print (time.sleep(5))\n",
    "\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \": Main script End\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:13:15.086813Z",
     "start_time": "2019-05-24T06:13:15.071928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>result_acc</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>forecast_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0 days 00:00:00.007974000</td>\n",
       "      <td>0 days 00:00:00.001071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0 days 00:00:00.004074000</td>\n",
       "      <td>0 days 00:00:00.000996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0 days 00:00:00.002997000</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0 days 00:00:00.002991000</td>\n",
       "      <td>0 days 00:00:00.000995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0 days 00:00:00.004002000</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c  result_acc                   fit_time              forecast_time\n",
       "0    0.01    0.485714  0 days 00:00:00.007974000  0 days 00:00:00.001071000\n",
       "1    0.10    0.828571  0 days 00:00:00.004074000  0 days 00:00:00.000996000\n",
       "2    1.00    0.914286  0 days 00:00:00.002997000  0 days 00:00:00.000000000\n",
       "3   10.00    0.942857  0 days 00:00:00.002991000  0 days 00:00:00.000995000\n",
       "4  100.00    0.942857  0 days 00:00:00.004002000  0 days 00:00:00.000000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\'+'Movies_and_TV_5_podbor_c_svm.csv', engine = 'python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:14:05.586935Z",
     "start_time": "2019-05-24T06:14:05.577959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-05-24 00:00:00.007974')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.to_datetime(df['fit_time'])-pd.to_datetime(df['forecast_time'])\n",
    "\n",
    "pd.to_datetime(df['fit_time'][0][7:],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments\n",
    "\n",
    "https://habr.com/ru/company/ods/blog/323890/#1-lineynaya-regressiya\n",
    "\n",
    "https://docplayer.ru/28834116-Otchet-po-zadaniyu-4-issledovanie-modeli-logistic-regression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "\n",
    "http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_(%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9,_%D0%9A.%D0%92.%D0%92%D0%BE%D1%80%D0%BE%D0%BD%D1%86%D0%BE%D0%B2)#.D0.9E.D1.81.D0.BD.D0.BE.D0.B2.D0.BD.D1.8B.D0.B5_.D0.BF.D0.BE.D0.BD.D1.8F.D1.82.D0.B8.D1.8F_.D0.B8_.D0.BF.D1.80.D0.B8.D0.BC.D0.B5.D1.80.D1.8B_.D0.BF.D1.80.D0.B8.D0.BA.D0.BB.D0.B0.D0.B4.D0.BD.D1.8B.D1.85_.D0.B7.D0.B0.D0.B4.D0.B0.D1.87\n",
    "\n",
    "\n",
    "\n",
    "ROC:\n",
    "https://basegroup.ru/community/articles/logistic\n",
    "\n",
    "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "\n",
    "https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
