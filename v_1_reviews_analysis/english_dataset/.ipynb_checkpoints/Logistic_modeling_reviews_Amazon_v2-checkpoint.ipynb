{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    # random elements in the list\n",
    "    random.shuffle(reviews_lst_good)\n",
    "    random.shuffle(reviews_lst_bad)  \n",
    "    \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "    for i in reviews_lst_good:\n",
    "#         reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "#         summary_lst.append (i['summary'])\n",
    "\n",
    "    for i in reviews_lst_bad:\n",
    "#         reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "#         summary_lst.append (i['summary'])\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "#     df['reviewerID'] = reviewerID_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "#     df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    # \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-100000]) + list(df[df['overall'] < 3]['reviewText'][:-100000])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-100000:]) + list(df[df['overall'] < 3]['reviewText'][-100000:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = TfidfVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-100000]) + list(df[df['overall'] < 3]['mark'][:-100000])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    print ('    ')\n",
    "    \n",
    "    \n",
    "    best_c_dict = {}\n",
    "    main_dict = {}\n",
    "    \n",
    "    \n",
    "    for c in [0.01, 0.05, 0.1, 0.25, 0.5, 1]:\n",
    "        lr = LogisticRegression(C=c)\n",
    "        lr.fit(X_train, y_train)\n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "        best_c_dict [c] = accuracy_score(y_val, lr.predict(X_val))\n",
    "        main_dict [c] = [filename, accuracy_score(y_val, lr.predict(X_val))]\n",
    "    \n",
    "    inverse = [(value, key) for key, value in best_c_dict.items()]\n",
    "    print (max(inverse)[1])\n",
    "\n",
    "    final_model = LogisticRegression(C=best_c_dict[max(inverse)[1]])\n",
    "    print ('Model use C = ', best_c_dict[max(inverse)[1]])\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score( list(df[df['overall'] > 3]['mark'][-100000:]) + list(df[df['overall'] < 3]['mark'][-100000:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad\n",
    "    \n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('/Volumes/GoogleDrive/Мой диск/Work/Experiment')\n",
    "\n",
    "for i in os.listdir('/Volumes/GoogleDrive/Мой диск/Work/Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints' and i == 'Electronics_5.json':\n",
    "        print (i)\n",
    "        print ('   ')\n",
    "        dict_main = classify_it ('/Volumes/GoogleDrive/Мой диск/Work/Experiment/' + i, 0.25)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_lst = []\n",
    "y_lst = []\n",
    "for i in dict_main:\n",
    "    x_lst.append(i)\n",
    "    y_lst.append(dict_main[i][1])\n",
    "\n",
    "plt.bar(x_lst, y_lst, align='center', alpha=0.3, width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
