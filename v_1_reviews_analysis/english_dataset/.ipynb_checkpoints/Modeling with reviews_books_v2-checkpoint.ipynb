{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:46:44.631691Z",
     "start_time": "2019-04-21T09:46:44.628344Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gengo.ai/datasets/15-free-sentiment-analysis-datasets-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:49:31.709058Z",
     "start_time": "2019-04-21T09:46:45.352508Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "i = 0\n",
    "reviews_lst_good= []\n",
    "reviews_lst_bad = []\n",
    "\n",
    "\n",
    "with open('/Volumes/GoogleDrive/Мой диск/Work/Experiment/Books_5.json', 'r') as f: # C:\\\\Users\\\\denis.pekhterev\\\\Downloads\\\\Experiment_old\\\\Books_5.json\n",
    "        for line in f:\n",
    "            if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                reviews_lst_good.append (json.loads(line))\n",
    "            \n",
    "            elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "            if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                break\n",
    "                \n",
    "random.shuffle(reviews_lst_good)\n",
    "random.shuffle(reviews_lst_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:50:09.551333Z",
     "start_time": "2019-04-21T09:50:06.058703Z"
    }
   },
   "outputs": [],
   "source": [
    "reviewerID_lst = []\n",
    "reviewerName_lst = []\n",
    "reviewText_lst = []\n",
    "overall_lst = []\n",
    "summary_lst = []\n",
    "\n",
    "# reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "for i in reviews_lst_good:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "for i in reviews_lst_bad:\n",
    "    reviewerID_lst.append (i['reviewerID'])\n",
    "    reviewText_lst.append (i['reviewText'])\n",
    "    overall_lst.append (i['overall'])\n",
    "    summary_lst.append (i['summary'])\n",
    "    \n",
    "df = pd.DataFrame ()\n",
    "\n",
    "df['reviewerID'] = reviewerID_lst\n",
    "# df['reviewerName'] = reviewerName_lst\n",
    "df['reviewText'] = reviewText_lst\n",
    "df['overall'] = overall_lst\n",
    "df['summary'] = summary_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:50:50.932280Z",
     "start_time": "2019-04-21T09:50:49.841373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500001\n"
     ]
    }
   ],
   "source": [
    "df ['mark'] = 0\n",
    "df.loc[df['overall'] > 3,'mark'] = 1\n",
    "\n",
    "print (len(df[df['mark'] > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:51:28.352502Z",
     "start_time": "2019-04-21T09:51:28.321247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewerID, reviewText, overall, summary, mark]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['mark'] != 0)&(df['mark'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:52:06.725543Z",
     "start_time": "2019-04-21T09:52:05.893071Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:52:57.109585Z",
     "start_time": "2019-04-21T09:52:57.101448Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is an excellent sequel to the novel, Kane and Abel. Archer once again is at his best. He remembers to intertwine key details of the book with Kane and Abel, and the reader easily recalls the suspense and the pure entertainment of Kane and Abel in Prodigal Daughter. Jeffrey Archer molds Florentyna into a very memorable character. Not many authors would have even tried to write a sequel Kane and Abel, but Jeffrey Archer makes a triumph of challenge. The result is The Prodigal Daughter. While it lacks some of the intensity of K&A, it is well worth the read.',\n",
       " 'Still reading this book  almost finished  great reading and many facts regarding this era..  well written book with a great insight into Prague which we have not seen a lot written about']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(df[df['overall'] > 3]['reviewText'][:2])\n",
    "reviews_train [:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T09:55:05.255546Z",
     "start_time": "2019-04-21T09:53:49.324282Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:02:04.897735Z",
     "start_time": "2019-04-21T09:56:13.721756Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:03:20.714791Z",
     "start_time": "2019-04-21T09:58:52.165Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:03:20.723786Z",
     "start_time": "2019-04-21T09:58:52.600Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = LogisticRegression(C=0.5)\n",
    "final_model.fit(X,  y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                        , final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:11:22.581790Z",
     "start_time": "2019-04-21T10:10:12.022Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:14:28.843384Z",
     "start_time": "2019-04-21T10:14:28.809700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_to_coef' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-59fac1a0e5e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m for best_positive in sorted(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeature_to_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     reverse=True)[:5]:\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_to_coef' is not defined"
     ]
    }
   ],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T10:11:22.598293Z",
     "start_time": "2019-04-21T10:10:13.292Z"
    }
   },
   "outputs": [],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:120]:\n",
    "    print (best_positive)\n",
    "\n",
    "writers = ['klausner','rollins','ehrman','gaiman','spong','olaf','steinbeck','harpercollins','discworld',\n",
    "'kingsolver','pratchett','maxon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T12:07:17.875433Z",
     "start_time": "2019-04-08T12:07:17.822327Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    \n",
    "    random.shuffle(reviews_lst_good)\n",
    "    random.shuffle(reviews_lst_bad)\n",
    "                    \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "    for i in reviews_lst_good:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    for i in reviews_lst_bad:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "    df['reviewerID'] = reviewerID_lst\n",
    "    # df['reviewerName'] = reviewerName_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "    df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = CountVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    \n",
    "    for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "        lr = LogisticRegression(C=c)\n",
    "        lr.fit(X_train, y_train)\n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "    \n",
    "    final_model = LogisticRegression(C=parametr)\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:07:18.337Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health_and_Personal_Care_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Health_and_Personal_Care_5.json\n",
      "Accuracy for C=0.01: 0.9375511763742562\n",
      "Accuracy for C=0.05: 0.94242316720345\n",
      "Accuracy for C=0.25: 0.9450161034990993\n",
      "Accuracy for C=0.5: 0.9445930454719144\n",
      "Accuracy for C=1: 0.9438561056826246\n",
      "Final Accuracy: 0.73015\n",
      "('deducted', 1.7656824591106735)\n",
      "('pleasantly', 1.656820137862464)\n",
      "('pleased', 1.6369400592065257)\n",
      "('skeptical', 1.5956846843153587)\n",
      "('highly', 1.5722485210054)\n",
      "('disappointing', -2.5610881508681285)\n",
      "('worthless', -2.4379621815169608)\n",
      "('disappointment', -2.143615023529117)\n",
      "('unacceptable', -2.0601684486255207)\n",
      "('poorly', -1.905376850288279)\n",
      "Movies_and_TV_5.json\n",
      "\n",
      "Подбор параметра для:  G:\\Мой диск\\Work\\Experiment\\Movies_and_TV_5.json\n",
      "Accuracy for C=0.01: 0.907810879772571\n",
      "Accuracy for C=0.05: 0.9136597187430822\n",
      "Accuracy for C=0.25: 0.9151918349275886\n",
      "Accuracy for C=0.5: 0.914830651644549\n",
      "Accuracy for C=1: 0.9139975998788288\n",
      "Final Accuracy: 0.88745\n",
      "('coulardeau', 2.4949225480924606)\n",
      "('quotable', 2.027263219530878)\n",
      "('crunches', 1.7436805584481667)\n",
      "('coz', 1.6879254905129906)\n",
      "('pleasantly', 1.6870842185236206)\n",
      "('kgharris', -2.3544545139492)\n",
      "('waste', -2.191112258674876)\n",
      "('promisingly', -2.1100479690920535)\n",
      "('snoozer', -2.081385107516871)\n",
      "('poorest', -2.05147707247044)\n",
      "Electronics_5.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.5)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:49.310Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.25)\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:50.132Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def classify_it(filename, parametr): \n",
    "    i = 0\n",
    "    reviews_lst_good= []\n",
    "    reviews_lst_bad = []\n",
    "\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if json.loads(line)['overall'] > 3 and len(reviews_lst_good)<=500000:\n",
    "                    reviews_lst_good.append (json.loads(line))\n",
    "\n",
    "                elif json.loads(line)['overall'] < 3 and len(reviews_lst_bad)<=500000:\n",
    "                    reviews_lst_bad.append (json.loads(line))\n",
    "\n",
    "                if len(reviews_lst_good) + len (reviews_lst_bad) == 1000000:\n",
    "                    break\n",
    "    reviews_lst_good = random.shuffle(reviews_lst_good)\n",
    "    reviews_lst_bad = random.shuffle(reviews_lst_bad)  \n",
    "    \n",
    "    reviewerID_lst = []\n",
    "    reviewerName_lst = []\n",
    "    reviewText_lst = []\n",
    "    overall_lst = []\n",
    "    summary_lst = []\n",
    "\n",
    "    # reviews_lst [0]['overall']<5 #['asin']for \n",
    "\n",
    "    for i in reviews_lst_good:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    for i in reviews_lst_bad:\n",
    "        reviewerID_lst.append (i['reviewerID'])\n",
    "        reviewText_lst.append (i['reviewText'])\n",
    "        overall_lst.append (i['overall'])\n",
    "        summary_lst.append (i['summary'])\n",
    "\n",
    "    df = pd.DataFrame ()\n",
    "\n",
    "    df['reviewerID'] = reviewerID_lst\n",
    "    # df['reviewerName'] = reviewerName_lst\n",
    "    df['reviewText'] = reviewText_lst\n",
    "    df['overall'] = overall_lst\n",
    "    df['summary'] = summary_lst\n",
    "    \n",
    "    df ['mark'] = 0\n",
    "    df.loc[df['overall'] > 3,'mark'] = 1\n",
    "    \n",
    "    reviews_train = list(df[df['overall'] > 3]['reviewText'][:-10000]) + list(df[df['overall'] < 3]['reviewText'][:-10000])\n",
    "    reviews_test = list(df[df['overall'] > 3]['reviewText'][-10000:]) + list(df[df['overall'] < 3]['reviewText'][-10000:])\n",
    "\n",
    "\n",
    "\n",
    "    reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "    reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "    \n",
    "    cv = TfidfVectorizer(binary=True)\n",
    "    cv.fit(reviews_train_clean)\n",
    "    X = cv.transform(reviews_train_clean)\n",
    "    X_test = cv.transform(reviews_test_clean)\n",
    "    \n",
    "    y = list(df[df['overall'] > 3]['mark'][:-10000]) + list(df[df['overall'] < 3]['mark'][:-10000])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, train_size = 0.75\n",
    "    )\n",
    "    \n",
    "    print ('Подбор параметра для: ', filename)\n",
    "    print ('    ')\n",
    "    \n",
    "    for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "        lr = LogisticRegression(C=c)\n",
    "        lr.fit(X_train, y_train)\n",
    "        print (\"Accuracy for C=%s: %s\" \n",
    "               % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "    \n",
    "    final_model = LogisticRegression(C=parametr)\n",
    "    final_model.fit(X,  y)\n",
    "    print (\"Final Accuracy: %s\" \n",
    "           % accuracy_score( list(df[df['overall'] > 3]['mark'][-10000:]) + list(df[df['overall'] < 3]['mark'][-10000:])\n",
    "                            , final_model.predict(X_test)))\n",
    "    \n",
    "    feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "        )\n",
    "    }\n",
    "    for best_positive in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True)[:5]:\n",
    "        print (best_positive)\n",
    "    for best_negative in sorted(\n",
    "        feature_to_coef.items(), \n",
    "        key=lambda x: x[1])[:5]:\n",
    "        print (best_negative)\n",
    "        \n",
    "    del reviews_lst_good\n",
    "    del reviews_lst_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:51.011Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment')\n",
    "\n",
    "for i in os.listdir('G:\\\\Мой диск\\\\Work\\\\Experiment'):\n",
    "    if i[-5:] != 'ipynb' and i != '.ipynb_checkpoints':\n",
    "        print (i)\n",
    "        print ('   ')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.25)\n",
    "        gc.collect()\n",
    "        print ('   ')\n",
    "        classify_it ('G:\\\\Мой диск\\\\Work\\\\Experiment\\\\' + i, 0.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:52.163Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "list = [20, 16, 10, 5];\n",
    "random.shuffle(list)\n",
    "print (\"Reshuffled list : \",  list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:53.755Z"
    }
   },
   "outputs": [],
   "source": [
    "# BackUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-08T12:23:54.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_json('Books_5.json')\n",
    "# import ijson\n",
    "# filename = \"Books_5.json\"\n",
    "# with open(filename, 'r') as f:\n",
    "#     objects = ijson.items(f, 'meta.view.columns.item')\n",
    "#     columns = list(objects)\n",
    "#     print (objects)\n",
    "# handle = open(\"Books_5.json\", \"r\")\n",
    "\n",
    "# while True:\n",
    "#     data = handle.read(20000)\n",
    "#     if not data:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "179.391px",
    "left": "1521px",
    "right": "20px",
    "top": "117px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
